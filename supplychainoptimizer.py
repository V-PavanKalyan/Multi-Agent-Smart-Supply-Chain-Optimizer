# -*- coding: utf-8 -*-
"""SupplyChainOptimizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xxxXr0_o1Aey30QA6pJUIoAHcnDmnjON
"""

!pip install openrouteservice pyowm # Install the openrouteservice and pyowm libraries using pip

!pip install langchain-google-genai # Install the langchain-google-genai library using pip

import os # Import the operating system module for interacting with the operating system
import json # Import the JSON module for working with JSON data
import pandas as pd # Import the pandas library and alias it as pd for data manipulation
import numpy as np # Import the numpy library and alias it as np for numerical operations
import matplotlib.pyplot as plt # Import the matplotlib.pyplot module and alias it as plt for creating plots
import plotly.express as px # Import the plotly.express module and alias it as px for creating interactive plots
import plotly.graph_objects as go # Import the plotly.graph_objects module and alias it as go for creating more detailed plotly plots
import folium # Import the folium library for creating interactive maps
import seaborn as sns # Import the seaborn library for statistical data visualization
from datetime import datetime, timedelta # Import datetime and timedelta from the datetime module for working with dates and times
from typing import Dict, List, Optional, Any, Union # Import type hints for better code readability and maintainability
import logging # Import the logging module for logging messages
import time # Import the time module for time-related functions
import random # Import the random module for generating random numbers
from dataclasses import dataclass, field # Import dataclass and field from the dataclasses module for creating data classes
from enum import Enum # Import Enum from the enum module for creating enumerations
import warnings # Import the warnings module for managing warnings
warnings.filterwarnings('ignore') # Ignore warning messages

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s') # Configure the logging system to display INFO level messages with a specific format
logger = logging.getLogger(__name__) # Get a logger instance for the current module

print("âœ… All packages installed successfully!") # Print a message indicating that all packages have been installed successfully

# For dynamic mode (with live APIs)
GEMINI_API_KEY = "AIzaSyD4bxgGDO04NvaxDnwdcDj77v9l_2iLUEE"
OPENROUTESERVICE_API_KEY = "eyJvcmciOiI1YjNjZTM1OTc4NTExMTAwMDFjZjYyNDgiLCJpZCI6ImM2NThkN2FhYzE0MjQ0OTk5NmVhMDAzYjc2ZjIwNDg5IiwiaCI6Im11cm11cjY0In0="
OPENWEATHERMAP_API_KEY = "bfd24ad836ede5acb0f61386aa189ef2"

STATIC_MODE = not (GEMINI_API_KEY and OPENROUTESERVICE_API_KEY and OPENWEATHERMAP_API_KEY) # Determine the operating mode (STATIC or DYNAMIC) based on whether API keys are available

if STATIC_MODE: # Check if the system is in STATIC_MODE
    print("ðŸ”§ Running in STATIC MODE (CSV data only, no API calls)") # Print a message indicating STATIC_MODE
else: # If not in STATIC_MODE (meaning it's in DYNAMIC_MODE)
    print("ðŸŒ Running in DYNAMIC MODE (with live API integrations)") # Print a message indicating DYNAMIC_MODE
    os.environ["GOOGLE_API_KEY"] = GEMINI_API_KEY # Set the GOOGLE_API_KEY environment variable for use with the Gemini API

# Load Inventory and Supplier data directly from CSV files
import pandas as pd

# Read CSV files (make sure inventory.csv and suppliers.csv are in the same directory as the notebook)
inventory_df = pd.read_csv('inventory.csv')
suppliers_df = pd.read_csv('suppliers.csv')

print("ðŸ“Š Data loaded successfully:")
print("\nInventory Data (first 5 rows):")
print(inventory_df.head())

print("\nSuppliers Data (first 5 rows):")
print(suppliers_df.head())

"""# **LLM initialization**"""

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage # Import necessary message types from langchain_core
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # Import prompt template and message placeholder
from langchain_core.runnables import RunnablePassthrough # Import RunnablePassthrough for chaining runnables
from langchain_core.output_parsers import StrOutputParser # Import StrOutputParser for parsing string output

if not STATIC_MODE: # Check if the system is NOT in STATIC_MODE (meaning it's in DYNAMIC_MODE)
    from langchain_google_genai import ChatGoogleGenerativeAI # Import ChatGoogleGenerativeAI for dynamic mode

    # Initialize Gemini model with specified parameters
    llm = ChatGoogleGenerativeAI(
        model="gemini-pro", # Specify the Gemini model to use
        temperature=0.1, # Set the temperature for controlling creativity
        api_key=GEMINI_API_KEY # Provide the API key for authentication
    )
else: # If the system IS in STATIC_MODE
    # Define a mock LLM class for static mode to simulate responses
    class MockLLM:
        def invoke(self, messages): # Define an invoke method to simulate a single response
            return AIMessage(content="Static mode response - using predefined logic") # Return a predefined static response

        def stream(self, messages): # Define a stream method to simulate a streaming response
            yield AIMessage(content="Static mode response - using predefined logic") # Yield a predefined static response

    llm = MockLLM() # Initialize the mock LLM

print("ðŸ¤– LLM initialized successfully!") # Print a message indicating successful LLM initialization

from datetime import datetime # Import the datetime class from the datetime module

class CommunicationBus: # Define a class named CommunicationBus
    def __init__(self): # Define the constructor for the CommunicationBus class
        self.messages = [] # Initialize an empty list to store messages

    def send(self, from_agent, to_agent, message_type, payload, reasoning): # Define a method to send a message
        msg = { # Create a dictionary to represent the message
            "timestamp": datetime.now().isoformat(), # Add the current timestamp to the message
            "from_agent": from_agent, # Add the sender agent's name to the message
            "to_agent": to_agent, # Add the recipient agent's name to the message
            "message_type": message_type, # Add the type of message to the message
            "payload": payload, # Add the message payload (data) to the message
            "reasoning_steps": reasoning # Add the reasoning steps to the message
        }
        self.messages.append(msg) # Append the message to the list of messages

    def fetch_for(self, agent_name): # Define a method to fetch messages for a specific agent
        return [m for m in self.messages if m["to_agent"] in [agent_name, "broadcast"]] # Return messages addressed to the agent or broadcast messages

    def get_all_logs(self): # Define a method to get all messages
        return self.messages # Return the list of all messages

"""# **Memory management system**"""

class AgentMemory: # Define a class named AgentMemory to manage agent memories
    """Persistent memory system for agents using JSON files""" # Add a docstring explaining the purpose of the class

    def __init__(self, agent_name: str): # Define the constructor for the AgentMemory class, taking the agent's name as input
        self.agent_name = agent_name # Store the agent's name
        self.memory_file = f"{agent_name.lower().replace(' ', '_')}_memory.json" # Create a filename for the memory file based on the agent's name
        self.memory = self._load_memory() # Load the memory from the file or initialize a new memory

    def _load_memory(self) -> Dict: # Define an internal method to load memory from the JSON file
        """Load memory from JSON file""" # Add a docstring explaining the purpose of the method
        try: # Start a try block to handle potential errors
            with open(self.memory_file, 'r') as f: # Open the memory file in read mode
                return json.load(f) # Load the JSON data from the file and return it
        except FileNotFoundError: # Handle the case where the file is not found
            return { # Return a new, empty memory structure
                "conversations": [], # Initialize an empty list for conversations
                "decisions": [], # Initialize an empty list for decisions
                "messages": [], # Initialize an empty list for messages
                "learning": {}, # Initialize an empty dictionary for learning data
                "performance_metrics": {}, # Initialize an empty dictionary for performance metrics
                "timestamp": datetime.now().isoformat() # Add the current timestamp
            }

    def save_memory(self): # Define a method to save the memory to the JSON file
        """Save memory to JSON file""" # Add a docstring explaining the purpose of the method
        self.memory["timestamp"] = datetime.now().isoformat() # Update the timestamp in the memory
        with open(self.memory_file, 'w') as f: # Open the memory file in write mode
            json.dump(self.memory, f, indent=2, default=str) # Dump the memory data to the file in JSON format with indentation

    def add_conversation(self, message: str, response: str): # Define a method to add a conversation to memory
        """Add conversation to memory""" # Add a docstring explaining the purpose of the method
        self.memory["conversations"].append({ # Append a new conversation entry to the conversations list
            "timestamp": datetime.now().isoformat(), # Add the current timestamp to the conversation entry
            "message": message, # Add the user's message to the conversation entry
            "response": response # Add the agent's response to the conversation entry
        })
        self.save_memory() # Save the updated memory to the file

    def add_decision(self, context: str, decision: str, reasoning: List[str], confidence: float): # Define a method to add a decision to memory
        """Add decision to memory""" # Add a docstring explaining the purpose of the method
        self.memory["decisions"].append({ # Append a new decision entry to the decisions list
            "timestamp": datetime.now().isoformat(), # Add the current timestamp to the decision entry
            "context": context, # Add the context of the decision
            "decision": decision, # Add the decision made
            "reasoning": reasoning, # Add the reasoning steps for the decision
            "confidence": confidence # Add the confidence score for the decision
        })
        self.save_memory() # Save the updated memory to the file

    def add_message(self, from_agent: str, to_agent: str, payload: Dict): # Define a method to add an inter-agent message to memory
        """ðŸ†• Add inter-agent message to memory""" # Add a docstring explaining the purpose of the method
        self.memory["messages"].append({ # Append a new message entry to the messages list
            "timestamp": datetime.now().isoformat(), # Add the current timestamp to the message entry
            "from": from_agent, # Add the sender of the message
            "to": to_agent, # Add the recipient of the message
            "payload": payload # Add the message payload (data)
        })
        self.save_memory() # Save the updated memory to the file

    def update_learning(self, key: str, value: Any): # Define a method to update learning data in memory
        """Update learning data""" # Add a docstring explaining the purpose of the method
        self.memory["learning"][key] = value # Update or add a key-value pair in the learning dictionary
        self.save_memory() # Save the updated memory to the file

    def get_recent_decisions(self, limit: int = 5) -> List[Dict]: # Define a method to get recent decisions from memory
        """Get recent decisions""" # Add a docstring explaining the purpose of the method
        return self.memory["decisions"][-limit:] # Return the last 'limit' number of decisions from the decisions list

print("ðŸ§  Memory management system initialized!") # Print a message indicating that the memory management system has been initialized

"""# **Inventory Management Agent**"""

class InventoryManagementAgent: # Define a class named InventoryManagementAgent
    """Agent responsible for inventory monitoring and stock predictions""" # Add a docstring explaining the agent's purpose

    def __init__(self, llm, bus=None): # Define the constructor for the InventoryManagementAgent class, taking llm and an optional bus as input
        self.llm = llm # Store the language model (llm) instance
        self.bus = bus # Store the communication bus instance (or None if not provided)
        self.memory = AgentMemory("Inventory Management Agent") # Initialize an AgentMemory instance for this agent
        self.name = "Inventory Management Agent" # Set the agent's name

    def analyze_inventory(self, inventory_df: pd.DataFrame) -> Dict: # Define a method to analyze inventory levels and predict stockouts
        """Analyze inventory levels and predict stockouts""" # Add a docstring explaining the method's purpose

        # Calculate days until stockout for each item
        inventory_df['days_until_stockout'] = (
            # Calculate days until stockout: current stock / monthly usage * 30 days (approximately)
            # If monthly usage is 0, set days until stockout to infinity
            inventory_df.apply(lambda row: row['current_stock'] / row['monthly_usage'] * 30 if row['monthly_usage'] > 0 else float('inf'), axis=1)
        ).round(0) # Round the result to the nearest whole number

        # Identify critical items (current stock <= reorder point)
        critical_items = inventory_df[inventory_df['current_stock'] <= inventory_df['reorder_point']]
        # Identify low stock items (current stock > reorder point AND days until stockout <= 14)
        low_stock_items = inventory_df[
            (inventory_df['current_stock'] > inventory_df['reorder_point']) & # Check if current stock is above reorder point
            (inventory_df['days_until_stockout'] <= 14) # Check if days until stockout is 14 or less
        ]

        # Create a dictionary to store the analysis results
        analysis = {
            "total_items": len(inventory_df), # Total number of items in the inventory
            "critical_items": len(critical_items), # Number of critical items
            "low_stock_items": len(low_stock_items), # Number of low stock items
            # Details of critical items (item_id, item_name, current_stock, reorder_point, days_until_stockout)
            "critical_item_details": critical_items[['item_id', 'item_name', 'current_stock', 'reorder_point', 'days_until_stockout']].to_dict('records'),
            # Details of low stock items (item_id, item_name, current_stock, days_until_stockout)
            "low_stock_details": low_stock_items[['item_id', 'item_name', 'current_stock', 'days_until_stockout']].to_dict('records'),
            "total_inventory_value": int(inventory_df['current_stock'].sum()), # Total sum of current stock across all items
            # Calculate average days to stockout for items with monthly usage > 0, handle case with no usage
            "average_days_to_stockout": float(inventory_df['days_until_stockout'][inventory_df['monthly_usage'] > 0].mean() if (inventory_df['monthly_usage'] > 0).any() else 0)
        }
        # Create a list of reasoning steps for the analysis
        reasoning = [
            f"Analyzed {analysis['total_items']} items", # Reasoning step: number of items analyzed
            f"Found {analysis['critical_items']} critical items below reorder point", # Reasoning step: number of critical items found
            f"Identified {analysis['low_stock_items']} items with low stock (< 14 days)", # Reasoning step: number of low stock items found
            f"Average days to stockout: {analysis['average_days_to_stockout']:.1f}" # Reasoning step: average days to stockout
        ]

        # Add the analysis decision to the agent's memory
        self.memory.add_decision(
            context="inventory_analysis", # Context of the decision
            decision="completed_inventory_analysis", # The decision made
            reasoning=reasoning, # The reasoning steps
            confidence=0.95 # Confidence level of the decision
        )
        # If a communication bus is available and there are critical items
        if self.bus and analysis["critical_items"] > 0:
            # Create a payload with critical item details
            payload = {"critical_items": analysis["critical_item_details"]}
            # Send an alert message to the "Supplier Agent" via the bus
            self.bus.send(
                from_agent=self.name, # Sender agent's name
                to_agent="Supplier Agent", # Recipient agent's name
                message_type="alert", # Type of message (alert)
                payload=payload, # The message payload
                reasoning=reasoning # The reasoning for sending the message
            )
            # Add the sent message to the agent's memory
            self.memory.add_message(
                from_agent=self.name, # Sender agent's name
                to_agent="Supplier Agent", # Recipient agent's name
                payload=payload # The message payload
            )

        return analysis # Return the analysis results

"""# **Supplier Agent**"""

class SupplierAgent: # Define a class named SupplierAgent
    """Agent responsible for evaluating suppliers""" # Add a docstring explaining the agent's purpose

    def __init__(self, llm, bus=None): # Define the constructor for the SupplierAgent class
        self.llm = llm # Store the language model (llm) instance
        self.bus = bus # Store the communication bus instance (or None if not provided)
        self.memory = AgentMemory("Supplier Agent") # Initialize an AgentMemory instance for this agent
        self.name = "Supplier Agent" # Set the agent's name

    def evaluate_suppliers(self, suppliers_df: pd.DataFrame, item_id: str) -> Dict: # Define a method to evaluate suppliers for a specific item
        """Evaluate suppliers for a given item""" # Add a docstring explaining the method's purpose

        relevant_suppliers = suppliers_df[suppliers_df['item_id'] == item_id] # Filter the suppliers DataFrame to get suppliers for the given item_id

        if relevant_suppliers.empty: # Check if there are no suppliers found for the item
            decision = { # Create a dictionary to represent the decision
                "item_id": item_id, # Add the item_id to the decision
                "recommended_supplier": None, # Set recommended_supplier to None
                "reason": "No suppliers found for this item" # Provide a reason for not finding suppliers
            }
            self.memory.add_decision( # Add the decision to the agent's memory
                context="supplier_evaluation", # Context of the decision
                decision="no_supplier_found", # The decision made
                reasoning=[f"No suppliers found for item {item_id}"], # Reasoning for the decision
                confidence=0.0 # Confidence level of the decision (low)
            )
            return decision # Return the decision

        best_supplier = relevant_suppliers.sort_values( # Find the best supplier based on reliability and price
            by=['reliability_score', 'price_per_unit'], # Sort by reliability (descending) and price (ascending)
            ascending=[False, True] # Sort order
        ).iloc[0] # Select the first row (best supplier)

        decision = { # Create a dictionary to represent the decision
            "item_id": item_id, # Add the item_id to the decision
            "recommended_supplier": best_supplier['supplier_name'], # Add the recommended supplier's name
            "price_per_unit": float(best_supplier['price_per_unit']), # Add the price per unit
            "lead_time_days": int(best_supplier['lead_time_days']), # Add the lead time in days
            "reliability_score": float(best_supplier['reliability_score']) # Add the reliability score
        }

        reasoning = [ # Create a list of reasoning steps for the decision
            f"Selected {best_supplier['supplier_name']} for item {item_id}", # Reasoning step: selected supplier
            f"Lead time: {best_supplier['lead_time_days']} days", # Reasoning step: lead time
            f"Price: {best_supplier['price_per_unit']}, Reliability: {best_supplier['reliability_score']}" # Reasoning step: price and reliability
        ]

        self.memory.add_decision( # Add the decision to the agent's memory
            context="supplier_evaluation", # Context of the decision
            decision=f"recommended_{best_supplier['supplier_name']}", # The decision made (recommended supplier)
            reasoning=reasoning, # The reasoning steps
            confidence=0.9 # Confidence level of the decision (high)
        )

        return decision # Return the decision

    def process_messages(self, suppliers_df: pd.DataFrame): # Define a method to process incoming messages for the supplier agent
        """Fetch and process inventory alerts from the bus""" # Add a docstring explaining the method's purpose

        if not self.bus: # Check if a communication bus is available
            return [] # Return an empty list if no bus is available

        responses = [] # Initialize an empty list to store responses
        messages = self.bus.fetch_for(self.name) # Fetch messages from the bus addressed to this agent

        for msg in messages: # Iterate through each fetched message
            if msg["message_type"] == "alert" and "critical_items" in msg["payload"]: # Check if the message is an alert and contains critical items
                critical_items = msg["payload"]["critical_items"] # Extract critical items from the message payload

                for item in critical_items: # Iterate through each critical item
                    result = self.evaluate_suppliers(suppliers_df, item["item_id"]) # Evaluate suppliers for the current critical item
                    responses.append(result) # Append the evaluation result to the responses list

                    self.memory.add_message( # Log the incoming message in the agent's memory
                        from_agent=msg["from_agent"], # Sender agent's name
                        to_agent=self.name, # Recipient agent's name (this agent)
                        payload=msg["payload"] # The message payload
                    )

                    if result["recommended_supplier"]: # Check if a recommended supplier was found
                        self.bus.send( # Send a proposal message to the "Planner Agent" via the bus
                            from_agent=self.name, # Sender agent's name (this agent)
                            to_agent="Planner Agent", # Recipient agent's name
                            message_type="proposal", # Type of message (proposal)
                            payload=result, # The message payload (supplier evaluation result)
                            reasoning=[f"Supplier {result['recommended_supplier']} chosen for {item['item_id']}"] # Reasoning for the proposal
                        )
                        self.memory.add_message( # Log the outgoing message in the agent's memory
                            from_agent=self.name, # Sender agent's name (this agent)
                            to_agent="Planner Agent", # Recipient agent's name
                            payload=result # The message payload
                        )

        return responses # Return the list of responses

"""# **RouteOptimization Agent**"""

import logging # Import the logging module for logging messages
from typing import List, Tuple, Dict # Import type hints for better code readability and maintainability

logger = logging.getLogger(__name__) # Get a logger instance for the current module

class RouteOptimizationAgent: # Define a class named RouteOptimizationAgent
    """Agent responsible for route planning and optimization""" # Add a docstring explaining the agent's purpose

    def __init__(self, llm, bus=None): # Define the constructor for the RouteOptimizationAgent class
        self.llm = llm # Store the language model (llm) instance
        self.bus = bus # Store the communication bus instance (or None if not provided)
        self.memory = AgentMemory("Route Optimization Agent") # Initialize an AgentMemory instance for this agent
        self.name = "Route Optimization Agent" # Set the agent's name

    def optimize_routes(self, locations: List[Tuple], use_api: bool = False) -> Dict: # Define a method to optimize delivery routes
        """Optimize delivery routes""" # Add a docstring explaining the method's purpose

        routes = None # Initialize routes to None

        if use_api and OPENROUTESERVICE_API_KEY and locations: # Check if API usage is enabled, API key is available, and locations are provided
            try: # Start a try block to handle potential errors
                import openrouteservice as ors # Import the openrouteservice library
                from openrouteservice.exceptions import ApiError # Import the ApiError exception
                client = ors.Client(key=OPENROUTESERVICE_API_KEY) # Initialize the OpenRouteService client with the API key

                coords = locations # Set the coordinates to the provided locations
                try: # Start a try block for the API call
                    routes = client.directions(coords, profile='driving-car', optimize_waypoints=True) # Call the OpenRouteService API to get optimized directions
                    if not routes or not routes.get('routes'): # Check if the API returned no routes
                        logger.warning("OpenRouteService API returned no routes.") # Log a warning
                        use_api = False # Fallback to mock mode

                except ApiError as e: # Handle OpenRouteService API errors
                    error_message = str(e) # Get the error message
                    if "Could not find routable point within a radius of 350.0 meters" in error_message: # Check for a specific error message
                        logger.error(f"OpenRouteService API call failed: 404 - Could not find routable point within the default 350-meter radius of a coordinate. Consider adjusting the location data or the radius limit if applicable. Original error: {error_message}") # Log a specific error message
                    else: # Handle other API errors
                        logger.error(f"OpenRouteService API call failed: {e}") # Log the API error
                    use_api = False # Fallback to mock mode
                except Exception as e: # Catch any other unexpected exceptions
                    logger.error(f"OpenRouteService API call failed unexpectedly: {e}") # Log the unexpected error
                    use_api = False # Fallback to mock mode

            except ImportError as e: # Handle ImportError if openrouteservice is not installed
                logger.error(f"OpenRouteService import failed: {e}") # Log the import error
                use_api = False # Fallback to mock mode
            except Exception as e: # Catch any other exceptions during initialization
                logger.error(f"OpenRouteService initialization failed: {e}") # Log the initialization error
                use_api = False # Fallback to mock mode

        if not use_api or routes is None or not routes.get('routes'): # Check if API was not used, or if no routes were returned
            logger.info("Falling back to mock route optimization.") # Log that the system is falling back to mock optimization
            def haversine_distance(lat1, lon1, lat2, lon2): # Define a helper function to calculate Haversine distance
                R = 6371 # Earth radius in kilometers
                dlat = np.radians(lat2 - lat1) # Convert latitude difference to radians
                dlon = np.radians(lon2 - lon1) # Convert longitude difference to radians
                a = np.sin(dlat/2)**2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon/2)**2 # Calculate intermediate value 'a'
                c = 2 * np.arcsin(np.sqrt(a)) # Calculate intermediate value 'c'
                return R * c # Return the Haversine distance

            total_distance = 0 # Initialize total distance to 0
            if len(locations) > 1: # Check if there is more than one location
                for i in range(len(locations) - 1): # Iterate through the locations
                    try: # Start a try block for distance calculation
                        lat1, lon1 = float(locations[i][0]), float(locations[i][1]) # Get latitude and longitude of the current location
                        lat2, lon2 = float(locations[i+1][0]), float(locations[i+1][1]) # Get latitude and longitude of the next location
                        total_distance += haversine_distance(lat1, lon1, lat2, lon2) # Add the distance between current and next location to total distance
                    except (ValueError, TypeError): # Handle ValueError or TypeError if coordinates are not numeric
                        logger.warning(f"Invalid coordinate format for Haversine calculation: {locations[i]}, {locations[i+1]}") # Log a warning about invalid coordinates

            distance = total_distance # Set distance to the total calculated distance
            duration = distance / 50 if distance > 0 else 0 # Calculate duration based on distance (assuming 50 km/h average speed), handle division by zero

        else: # If API was used and returned routes
            distance = routes['routes'][0]['summary']['distance'] / 1000  # Get distance in km from API response
            duration = routes['routes'][0]['summary']['duration'] / 3600  # Get duration in hours from API response


        fuel_cost = distance * 0.15 # Calculate fuel cost (assuming $0.15 per km)
        driver_cost = duration * 25 # Calculate driver cost (assuming $25 per hour)
        total_cost = fuel_cost + driver_cost # Calculate total cost

        analysis = { # Create a dictionary to store the route analysis results
            "route_id": f"R-{datetime.now().strftime('%Y%m%d-%H%M%S')}", # Generate a unique route ID
            "total_distance_km": round(distance, 2), # Add total distance in km (rounded to 2 decimal places)
            "estimated_duration_hours": round(duration, 2), # Add estimated duration in hours (rounded to 2 decimal places)
            "fuel_cost_usd": round(fuel_cost, 2), # Add fuel cost in USD (rounded to 2 decimal places)
            "driver_cost_usd": round(driver_cost, 2), # Add driver cost in USD (rounded to 2 decimal places)
            "total_cost_usd": round(total_cost, 2), # Add total cost in USD (rounded to 2 decimal places)
            "waypoints": len(locations), # Add the number of waypoints (locations)
            "efficiency_score": min(1.0, 100 / (distance + duration * 10) if (distance + duration * 10) > 0 else 0) # Calculate an efficiency score
        }

        reasoning = [ # Create a list of reasoning steps for the route optimization
            f"Optimized route for {len(locations)} locations", # Reasoning step: number of locations optimized
            f"Distance: {analysis['total_distance_km']} km", # Reasoning step: total distance
            f"Duration: {analysis['estimated_duration_hours']} hours", # Reasoning step: estimated duration
            f"Cost: ${analysis['total_cost_usd']}" # Reasoning step: total cost
        ]

        self.memory.add_decision( # Add the route optimization decision to the agent's memory
            context="route_optimization", # Context of the decision
            decision="optimized_delivery_route", # The decision made
            reasoning=reasoning, # The reasoning steps
            confidence=0.85 if use_api else 0.5 # Confidence level of the decision (higher if API was used)
        )
        if self.bus: # Check if a communication bus is available
             payload = analysis.copy() # Create a copy of the analysis results as the payload
             self.bus.send( # Send an update message to the "Planner Agent" via the bus
                 from_agent=self.name, # Sender agent's name (this agent)
                 to_agent="Planner Agent", # Recipient agent's name
                 message_type="update", # Type of message (update)
                 payload=payload, # The message payload
                 reasoning=reasoning # The reasoning for sending the message
             )
             self.memory.add_message(self.name, "Planner Agent", payload) # Log the outgoing message in the agent's memory


        return analysis # Return the analysis results

    def process_messages(self, locations: List[Tuple], use_api: bool = False) -> Dict: # Define a method to process incoming messages and adjust routes
        """Check for risk alerts and adjust routes accordingly""" # Add a docstring explaining the method's purpose
        if not locations: # Check if the locations list is empty
             logger.warning("RouteOptimizationAgent received empty locations list.") # Log a warning
             return {} # Return an empty dictionary

        base_route = self.optimize_routes(locations, use_api=use_api) # Optimize the base route

        if not self.bus: # Check if a communication bus is available
            return base_route # Return the base route if no bus is available

        messages = self.bus.fetch_for(self.name) # Fetch messages from the bus addressed to this agent
        adjusted_route = base_route.copy() # Create a copy of the base route to store adjustments

        for msg in messages: # Iterate through each fetched message
            if msg["message_type"] == "alert" and msg["payload"].get("risk_type"): # Check if the message is an alert and contains a risk type
                risk = msg["payload"]["risk_type"].lower() # Get the risk type in lowercase

                if "flood" in risk: # Check if the risk is related to flood
                    adjusted_route["status"] = "rerouted_due_to_flood" # Set the status to indicate rerouting due to flood
                    adjusted_route["estimated_duration_hours"] = adjusted_route.get("estimated_duration_hours", 0) + 5 # Increase estimated duration
                    adjusted_route["total_cost_usd"] = adjusted_route.get("total_cost_usd", 0) + 50 # Increase total cost
                    reasoning = ["Flood detected: added 5 hours delay, $50 extra cost"] # Reasoning for the adjustment

                elif "strike" in risk: # Check if the risk is related to a strike
                    adjusted_route["status"] = "rerouted_due_to_strike" # Set the status to indicate rerouting due to strike
                    adjusted_route["estimated_duration_hours"] = adjusted_route.get("estimated_duration_hours", 0) + 8 # Increase estimated duration
                    adjusted_route["total_cost_usd"] = adjusted_route.get("total_cost_usd", 0) + 100 # Increase total cost
                    reasoning = ["Strike detected: rerouting with 8 hours delay, $100 extra"] # Reasoning for the adjustment

                elif "weather" in risk or "rain" in risk or "cloudy" in risk or "overcast" in risk or "sunny" in risk: # Check if the risk is related to weather
                     adjusted_route["status"] = f"route_adjusted_due_to_{risk.replace(' ', '_')}" # Set the status to indicate route adjustment due to weather
                     adjusted_route["estimated_duration_hours"] = adjusted_route.get("estimated_duration_hours", 0) + 1 # Slightly increase estimated duration
                     adjusted_route["total_cost_usd"] = adjusted_route.get("total_cost_usd", 0) + 20 # Slightly increase total cost
                     reasoning = [f"Weather risk detected: {risk}, adjusting route slightly"] # Reasoning for the adjustment

                else: # Handle other types of risks
                    reasoning = [f"Risk detected: {risk}, adjusting route"] # Reasoning for the adjustment
                    adjusted_route["status"] = f"rerouted_due_to_{risk.replace(' ', '_')}" # Set the status to indicate rerouting due to the risk


                self.memory.add_message(msg["from_agent"], self.name, msg["payload"]) # Log the incoming message in the agent's memory

                self.bus.send( # Send an update message to the "Planner Agent" via the bus
                    from_agent=self.name, # Sender agent's name (this agent)
                    to_agent="Planner Agent", # Recipient agent's name
                    message_type="update", # Type of message (update)
                    payload=adjusted_route, # The message payload (adjusted route data)
                    reasoning=reasoning # The reasoning for sending the message
                )

                self.memory.add_message(self.name, "Planner Agent", adjusted_route) # Log the outgoing message in the agent's memory

        return adjusted_route # Return the adjusted route data

"""# **RiskManagement Agent**"""

import logging # Import the logging module for logging messages
import random # Import the random module for generating random numbers
from typing import List, Dict, Tuple, Optional # Import type hints for better code readability and maintainability

logger = logging.getLogger(__name__) # Get a logger instance for the current module

class RiskManagementAgent: # Define a class named RiskManagementAgent
    """Agent responsible for risk assessment and mitigation""" # Add a docstring explaining the agent's purpose

    def __init__(self, llm, bus=None): # Define the constructor for the RiskManagementAgent class
        self.llm = llm # Store the language model (llm) instance
        self.bus = bus # Store the communication bus instance (or None if not provided)
        self.memory = AgentMemory("Risk Management Agent") # Initialize an AgentMemory instance for this agent
        self.name = "Risk Management Agent" # Set the agent's name

    def assess_risks(self, locations: List[Tuple], use_api: bool = False) -> Dict: # Define a method to assess various supply chain risks
        """Assess various supply chain risks""" # Add a docstring explaining the method's purpose

        weather_risks: List[Dict] = [] # Initialize an empty list to store weather risks
        pyowm_imported = False # Initialize a flag to track if pyowm was imported successfully

        if use_api and OPENWEATHERMAP_API_KEY: # Check if API usage is enabled and the OpenWeatherMap API key is available
            try: # Start a try block to handle potential errors
                import pyowm # Import the pyowm library
                from pyowm.commons import exceptions # Import exceptions from pyowm
                pyowm_imported = True # Set the flag to True if import is successful

                owm = pyowm.OWM(OPENWEATHERMAP_API_KEY) # Initialize the OpenWeatherMap client with the API key
                mgr = owm.weather_manager() # Get the weather manager from the client

                if locations: # Check if locations are provided
                    for lat_raw, lon_raw in locations[:3]: # Iterate through the first 3 locations (to avoid excessive API calls)
                        try: # Start a try block for coordinate conversion
                            lat = float(lat_raw) # Convert latitude to float
                            lon = float(lon_raw) # Convert longitude to float
                        except (TypeError, ValueError): # Handle TypeError or ValueError if coordinates are not numeric
                            logger.error(f"Weather API failed: Non-numeric coords lat={lat_raw}, lon={lon_raw}") # Log an error message
                            weather_risks.append(self._mock_weather_risk(lat_raw, lon_raw)) # Add a mock weather risk entry
                            continue # Skip to the next location

                        try: # Start a try block for the API call
                            obs = mgr.weather_at_coords(lat, lon) # Get weather observation at the given coordinates
                            weather = obs.weather # Get the weather details from the observation
                        except (exceptions.UnauthorizedError, exceptions.BadRequestError, exceptions.NotFoundError) as e: # Handle specific pyowm API errors
                            logger.error(f"Weather API call failed for ({lat:.2f}, {lon:.2f}): {e}") # Log the API error
                            use_api = False # Fallback to mock mode
                            break # Exit the loop if API call fails
                        except Exception as e: # Catch any other unexpected exceptions during the API call
                            logger.error(f"Weather API failed unexpectedly for ({lat:.2f}, {lon:.2f}): {e}") # Log the unexpected error
                            weather_risks.append(self._mock_weather_risk(lat, lon)) # Add a mock weather risk entry
                            continue # Continue to the next location
                        has_rain = bool(getattr(weather, "rain", {}) or {}) # Check if there is rain data
                        has_snow = bool(getattr(weather, "snow", {}) or {}) # Check if there is snow data
                        clouds_coverage = getattr(weather, "clouds", 0) or 0 # Get cloud coverage, default to 0 if not available

                        risk_level = "low" # Initialize risk level to low
                        condition = getattr(weather, "status", "Unknown") # Get the weather condition status
                        detailed_condition = getattr(weather, "detailed_status", "Unknown") # Get the detailed weather condition status

                        if has_rain or has_snow or "thunderstorm" in detailed_condition.lower() or "squalls" in detailed_condition.lower() or "tornado" in detailed_condition.lower(): # Check for conditions indicating high risk
                            risk_level = "high" # Set risk level to high
                        elif "drizzle" in detailed_condition.lower() or "fog" in detailed_condition.lower() or "mist" in detailed_condition.lower() or "haze" in detailed_condition.lower() or "clouds" in condition.lower() or "overcast" in condition.lower(): # Check for conditions indicating medium risk
                             risk_level = "medium" # Set risk level to medium
                        elif isinstance(clouds_coverage, (int, float)) and clouds_coverage > 75: # Check for high cloud coverage indicating medium risk
                             risk_level = "medium" # Set risk level to medium
                        elif "clear" in condition.lower() or "sunny" in condition.lower(): # Check for clear or sunny conditions indicating low risk
                            risk_level = "low" # Set risk level to low
                        else: # Handle unhandled weather conditions
                             risk_level = "medium" # Set risk level to medium by default for unhandled conditions
                             logger.warning(f"Unhandled weather condition '{condition}' ('{detailed_condition}') for risk assessment.") # Log a warning for unhandled conditions


                        weather_risks.append({ # Append the weather risk details to the list
                            "location": f"{lat:.2f}, {lon:.2f}", # Add the location coordinates
                            "condition": condition, # Add the weather condition status
                            "detailed_condition": detailed_condition, # Add the detailed weather condition status
                            "risk_level": risk_level, # Add the assessed risk level
                            "mitigation": "Monitor conditions, have backup routes ready" # Add recommended mitigation steps
                        })
                else: # If no locations are provided
                     logger.info("No locations provided for weather risk assessment.") # Log an info message


            except ImportError as e: # Handle ImportError if pyowm is not installed
                logger.error(f"pyowm import failed: {e}") # Log the import error
                use_api = False # Fallback to mock mode
            except Exception as e: # Catch any other exceptions during pyowm setup/initialization
                logger.error(f"Weather API setup/initialization failed: {e}") # Log the setup/initialization error
                use_api = False # Fallback to mock mode

        if not use_api and locations: # Check if API was not used and locations are available
            logger.info("Falling back to mock weather risk assessment.") # Log that the system is falling back to mock assessment
            mock_conditions = ["Clear", "Cloudy", "Light Rain", "Sunny", "Overcast"] # Define a list of mock weather conditions
            for lat, lon in locations[:min(len(locations), 3)]: # Iterate through the first 3 locations or fewer if less than 3
                weather_risks.append(self._mock_weather_risk(lat, lon, mock_conditions)) # Add a mock weather risk entry
        elif not locations: # If no locations are provided
             logger.info("Skipping mock weather risk assessment as no locations were provided.") # Log an info message


        supplier_risks = [ # Define a list of predefined supplier risks
            {
                "risk_type": "supplier_delay", # Type of risk
                "probability": 0.15, # Probability of the risk occurring
                "impact": "medium", # Impact level of the risk
                "mitigation": "Maintain safety stock, diversify suppliers" # Recommended mitigation steps
            }
        ]

        transport_risks = [ # Define a list of predefined transport risks
            {
                "risk_type": "traffic_congestion", # Type of risk
                "probability": 0.25, # Probability of the risk occurring
                "impact": "low", # Impact level of the risk
                "mitigation": "Use real-time traffic data, flexible delivery windows" # Recommended mitigation steps
            }
        ]

        analysis = { # Create a dictionary to store the risk analysis results
            "weather_risks": weather_risks, # Add the list of weather risks
            "supplier_risks": supplier_risks, # Add the list of supplier risks
            "transport_risks": transport_risks, # Add the list of transport risks
            "overall_risk_level": self._calculate_overall_risk(weather_risks, supplier_risks, transport_risks), # Calculate and add the overall risk level
            "recommended_actions": [ # Add a list of recommended actions
                "Monitor weather conditions closely", # Recommended action
                "Maintain emergency contact with suppliers", # Recommended action
                "Have contingency routes prepared", # Recommended action
                "Keep safety stock for critical items" # Recommended action
            ]
        }

        reasoning = [ # Create a list of reasoning steps for the risk assessment
            f"Checked {len(weather_risks)} weather risks", # Reasoning step: number of weather risks checked
            f"Identified {len(supplier_risks)} supplier risks", # Reasoning step: number of supplier risks identified
            f"Overall risk: {analysis['overall_risk_level']}", # Reasoning step: overall risk level
            f"Mitigation actions: {len(analysis['recommended_actions'])}" # Reasoning step: number of mitigation actions
        ]

        self.memory.add_decision( # Add the risk assessment decision to the agent's memory
            context="risk_assessment", # Context of the decision
            decision="completed_risk_analysis", # The decision made
            reasoning=reasoning, # The reasoning steps
            confidence=0.78 if use_api else 0.4 # Confidence level of the decision (higher if API was used)
        )

        if self.bus: # Check if a communication bus is available
            if weather_risks: # Check if there are any weather risks
                for wr in weather_risks: # Iterate through each weather risk
                    if wr.get("risk_level") in ["high", "medium"]: # Check if the risk level is high or medium
                        condition_str = str(wr.get("condition", "unknown_condition")) # Get the weather condition status as a string
                        detailed_condition_str = str(wr.get("detailed_condition", "unknown_condition")) # Get the detailed weather condition status as a string
                        location_str = str(wr.get("location", "unknown_location")) # Get the location as a string

                        payload = { # Create a dictionary to represent the message payload
                            "risk_type": condition_str.lower(), # Add the risk type (lowercase condition)
                            "detailed_risk_type": detailed_condition_str.lower(), # Add the detailed risk type (lowercase detailed condition)
                            "location": location_str, # Add the location
                            "details": wr # Add the detailed weather risk information
                            }

                        self.bus.send( # Send an alert message to the "Route Optimization Agent" via the bus
                            from_agent=self.name, # Sender agent's name (this agent)
                            to_agent="Route Optimization Agent", # Recipient agent's name
                            message_type="alert", # Type of message (alert)
                            payload=payload, # The message payload
                            reasoning=[f"Risk detected at {location_str}: {detailed_condition_str} ({wr.get('risk_level', 'unknown')})"] # Reasoning for sending the message
                        )
                        self.memory.add_message(self.name, "Route Optimization Agent", payload) # Log the outgoing message in the agent's memory

                        self.bus.send( # Send an alert message to the "Planner Agent" via the bus
                            from_agent=self.name, # Sender agent's name (this agent)
                            to_agent="Planner Agent", # Recipient agent's name
                            message_type="alert", # Type of message (alert)
                            payload=payload, # The message payload
                            reasoning=["Planner must consider alternative suppliers/routes due to risk"] # Reasoning for sending the message
                        )
                        self.memory.add_message(self.name, "Planner Agent", payload) # Log the outgoing message in the agent's memory
            else: # If there are no weather risks
                logger.info("No weather risks to report via communication bus.") # Log an info message


        return analysis # Return the risk analysis results

    def _mock_weather_risk(self, lat: Optional[float], lon: Optional[float], mock_conditions=None) -> Dict: # Define an internal method to create a consistent mock weather risk entry
        """Create a consistent mock weather risk entry.""" # Add a docstring explaining the method's purpose
        if mock_conditions is None: # Check if mock_conditions list is not provided
            mock_conditions = ["Clear", "Cloudy", "Light Rain", "Sunny", "Overcast"] # Use a default list of mock conditions
        condition = random.choice(mock_conditions) # Randomly select a weather condition from the list
        risk_level = "high" if "Rain" in condition else ("low" if condition == "Clear" or condition == "Sunny" else "medium") # Determine risk level based on the selected condition

        try: # Start a try block for formatting location string
            loc_str = f"{float(lat):.2f}, {float(lon):.2f}" # Format the location string with latitude and longitude
        except (TypeError, ValueError): # Handle TypeError or ValueError if coordinates are not numeric
            loc_str = f"{lat}, {lon}" # Use the raw coordinates if formatting fails

        return { # Return a dictionary representing the mock weather risk entry
            "location": loc_str, # Add the location string
            "condition": condition, # Add the weather condition
            "detailed_condition": condition, # Add the detailed weather condition (same as condition for mock)
            "risk_level": risk_level, # Add the assessed risk level
            "mitigation": "Monitor conditions, consider alternative routes" # Add recommended mitigation steps
        }

    def _calculate_overall_risk(self, weather_risks, supplier_risks, transport_risks) -> str: # Define an internal method to calculate the overall risk level
        """Calculate overall risk level""" # Add a docstring explaining the method's purpose
        high_or_medium_weather_risks = len([r for r in weather_risks if r.get('risk_level') in ['high', 'medium']]) # Count weather risks with high or medium risk levels
        if any(r.get('risk_level') == 'high' for r in weather_risks): # Check if any weather risk has a high risk level
            return "high" # Return "high" if there is any high weather risk
        elif high_or_medium_weather_risks >= 2: # Check if there are two or more high or medium weather risks
            return "medium" # Return "medium" if there are two or more high or medium weather risks
        else: # If none of the above conditions are met
            return "low" # Return "low"

"""
# **PlannerManager Agent**

"""

class PlannerManagerAgent: # Define a class named PlannerManagerAgent
    """Central agent that coordinates all other agents and manages user interaction""" # Add a docstring explaining the agent's purpose

    def __init__(self, llm, bus): # Define the constructor for the PlannerManagerAgent class
        self.llm = llm # Store the language model (llm) instance
        self.bus = bus # Store the communication bus instance
        self.memory = AgentMemory("Planner Manager Agent") # Initialize an AgentMemory instance for this agent
        self.name = "Planner Manager Agent" # Set the agent's name
        self.inventory_agent = InventoryManagementAgent(llm, bus) # Initialize the InventoryManagementAgent
        self.supplier_agent = SupplierAgent(llm, bus) # Initialize the SupplierAgent
        self.route_agent = RouteOptimizationAgent(llm, bus) # Initialize the RouteOptimizationAgent
        self.risk_agent = RiskManagementAgent(llm, bus) # Initialize the RiskManagementAgent

        self.shared_scratchpad = { # Initialize a shared scratchpad dictionary to store temporary data
            "session_id": datetime.now().strftime("%Y%m%d_%H%M%S"), # Generate a unique session ID
            "messages": [], # Initialize an empty list for messages
            "agent_outputs": {}, # Initialize an empty dictionary for agent outputs
            "user_interactions": [] # Initialize an empty list for user interactions
        }

    def process_user_query(self, query: str) -> Dict: # Define a method to process user queries
        """Process user query and coordinate agent responses""" # Add a docstring explaining the method's purpose

        timestamp = datetime.now().isoformat() # Get the current timestamp
        self.shared_scratchpad["user_interactions"].append({ # Append the user interaction to the scratchpad
            "timestamp": timestamp, # Add the timestamp
            "from": "user", # Indicate the source is the user
            "to": "Planner Agent", # Indicate the recipient is the Planner Agent
            "message_type": "query", # Indicate the message type is a query
            "payload": {"question": query}, # Add the user's query as the payload
            "response": None # Initialize the response as None
        })

        response_data = { # Initialize a dictionary to store the response data
            "query": query, # Add the original query
            "timestamp": timestamp, # Add the timestamp
            "analysis_performed": [], # Initialize an empty list for performed analyses
            "recommendations": [], # Initialize an empty list for recommendations
            "clarifications": [], # Initialize an empty list for clarifications
            "bus_messages": [] # Initialize an empty list for bus messages
        }

        try: # Start a try block to handle potential errors
            inventory_df = pd.read_csv('inventory.csv') # Load inventory data from the CSV file
            suppliers_df = pd.read_csv('suppliers.csv') # Load supplier data from the CSV file

            inventory_analysis = self.inventory_agent.analyze_inventory(inventory_df) # Call the Inventory Agent to analyze inventory
            self.shared_scratchpad["agent_outputs"]["inventory"] = inventory_analysis # Store the inventory analysis results in the scratchpad
            response_data["analysis_performed"].append("inventory_analysis") # Add 'inventory_analysis' to the list of performed analyses

            critical_items = [item['item_id'] for item in inventory_analysis['critical_item_details']] # Get the item IDs of critical items
            low_stock_items = [item['item_id'] for item in inventory_analysis['low_stock_details']] # Get the item IDs of low stock items
            required_items = list(set(critical_items + low_stock_items)) # Combine critical and low stock items, removing duplicates

            if required_items: # Check if there are any required items
                supplier_responses = self.supplier_agent.process_messages(suppliers_df) # Call the Supplier Agent to process messages and evaluate suppliers
                self.shared_scratchpad["agent_outputs"]["supplier"] = {"recommended_suppliers": supplier_responses} # Store the supplier responses in the scratchpad
                response_data["analysis_performed"].append("supplier_analysis") # Add 'supplier_analysis' to the list of performed analyses

            item_locations = [] # Initialize an empty list to store locations of critical/low stock items
            for item in inventory_analysis['critical_item_details'] + inventory_analysis['low_stock_details']: # Iterate through critical and low stock item details
                item_id = item['item_id'] # Get the item ID
                matching_row = inventory_df[inventory_df['item_id'] == item_id].iloc[0] # Find the corresponding row in the inventory DataFrame
                item_locations.append((matching_row['location_lat'], matching_row['location_lon'])) # Append the location coordinates to the list

            if item_locations: # Check if there are any item locations
                risk_analysis = self.risk_agent.assess_risks(item_locations, use_api=not STATIC_MODE) # Call the Risk Agent to assess risks
                self.shared_scratchpad["agent_outputs"]["risk"] = risk_analysis # Store the risk analysis results in the scratchpad
                response_data["analysis_performed"].append("risk_assessment") # Add 'risk_assessment' to the list of performed analyses

                route_analysis = self.route_agent.process_messages(item_locations, use_api=not STATIC_MODE) # Call the Route Optimization Agent to process messages and optimize routes
                self.shared_scratchpad["agent_outputs"]["route"] = route_analysis # Store the route analysis results in the scratchpad
                response_data["analysis_performed"].append("route_optimization") # Add 'route_optimization' to the list of performed analyses

            bus_messages = self.bus.fetch_for("Planner Agent") # Fetch messages addressed to the Planner Agent from the communication bus
            response_data["bus_messages"] = bus_messages # Add the fetched bus messages to the response data
            self.shared_scratchpad["messages"].extend(bus_messages) # Extend the messages in the scratchpad with the bus messages

            response_data["recommendations"] = self._generate_recommendations() # Generate recommendations based on agent outputs

            response_msg = self._format_response(response_data) # Format the final response message
            self.shared_scratchpad["user_interactions"][-1]["response"] = response_msg # Add the formatted response to the last user interaction in the scratchpad
            self.memory.add_conversation(query, response_msg) # Add the user query and the generated response to the agent's memory

            return response_data # Return the complete response data

        except Exception as e: # Catch any exceptions that occur during processing
            error_msg = f"Error processing query: {str(e)}" # Create an error message
            logger.error(error_msg) # Log the error message
            response_data["error"] = error_msg # Add the error message to the response data
            return response_data # Return the response data with the error

    def _generate_recommendations(self) -> List[str]: # Define an internal method to generate recommendations
        """Generate recommendations based on agent outputs""" # Add a docstring explaining the method's purpose
        recommendations = [] # Initialize an empty list to store recommendations
        agent_outputs = self.shared_scratchpad.get("agent_outputs", {}) # Get the agent outputs from the scratchpad

        if "inventory" in agent_outputs: # Check if inventory analysis results are available
            inv = agent_outputs["inventory"] # Get the inventory analysis data
            if inv["critical_items"] > 0: # Check if there are any critical items
                recommendations.append(f"URGENT: Restock {inv['critical_items']} critical items immediately") # Add a recommendation to restock critical items
            if inv["low_stock_items"] > 0: # Check if there are any low stock items
                 recommendations.append(f"Monitor {inv['low_stock_items']} items with low stock") # Add a recommendation to monitor low stock items


        if "supplier" in agent_outputs and agent_outputs["supplier"].get("recommended_suppliers"): # Check if supplier recommendations are available
            suppliers = agent_outputs["supplier"]["recommended_suppliers"] # Get the recommended suppliers data
            if suppliers: # Check if there are any recommended suppliers
                 recommendations.append(f"Consider recommended suppliers for critical items.") # Add a general recommendation about recommended suppliers
                 for sup in suppliers: # Iterate through each recommended supplier
                     recommendations.append(f"- {sup['recommended_supplier']} for {sup['item_id']} (Lead Time: {sup['lead_time_days']} days, Price: ${sup['price_per_unit']:.2f})") # Add a specific recommendation for each supplier and item

        if "route" in agent_outputs: # Check if route optimization results are available
            route = agent_outputs["route"] # Get the route optimization data
            recommendations.append(f"Optimal route calculated: {route['total_distance_km']} km, {route['estimated_duration_hours']:.1f} hours, ${route['total_cost_usd']:.2f} cost.") # Add a recommendation about the optimal route
            if route.get("status") and "rerouted" in route["status"]: # Check if the route was rerouted due to risk
                 recommendations.append(f"Route adjusted due to risk: {route['status']}") # Add a recommendation indicating the route was adjusted

        if "risk" in agent_outputs: # Check if risk analysis results are available
            risk = agent_outputs["risk"] # Get the risk analysis data
            recommendations.append(f"Overall risk level: {risk['overall_risk_level'].upper()}.") # Add a recommendation about the overall risk level
            for wr in risk["weather_risks"]: # Iterate through each weather risk
                 if wr["risk_level"] in ["high", "medium"]: # Check if the weather risk level is high or medium
                     recommendations.append(f"Weather risk at {wr['location']}: {wr['condition']} - Mitigation: {wr['mitigation']}") # Add a recommendation about specific weather risks and their mitigation

        if not recommendations: # Check if no recommendations were generated
            recommendations.append("Analysis complete. No critical issues detected.") # Add a message indicating no critical issues
            recommendations.append("Consider performing a comprehensive analysis regularly.") # Add a general recommendation for regular analysis

        return recommendations # Return the list of recommendations

    def _format_response(self, response_data: Dict) -> str: # Define an internal method to format the response
        """Format the final response based on analysis results""" # Add a docstring explaining the method's purpose
        formatted_response = f"Supply Chain Analysis Results (Session ID: {self.shared_scratchpad['session_id']}):\n\n" # Initialize the formatted response string with the session ID

        if response_data.get("analysis_performed"): # Check if any analysis was performed
            formatted_response += "Analysis Performed: " + ", ".join(response_data["analysis_performed"]) + "\n\n" # Add the list of performed analyses to the response

        if response_data.get("recommendations"): # Check if there are any recommendations
            formatted_response += "Recommendations:\n" # Add a "Recommendations" header
            for rec in response_data["recommendations"]: # Iterate through each recommendation
                formatted_response += f"- {rec}\n" # Add each recommendation as a list item
            formatted_response += "\n" # Add a newline for spacing

        if response_data.get("bus_messages"): # Check if there are any bus messages
            formatted_response += "Inter-Agent Communication:\n" # Add an "Inter-Agent Communication" header
            for msg in response_data["bus_messages"]: # Iterate through each bus message
                formatted_response += f"- From {msg['from_agent']} to {msg['to_agent']} ({msg['message_type']}): {msg['payload']}\n" # Add each message details to the response
            formatted_response += "\n" # Add a newline for spacing

        if response_data.get("error"): # Check if there is an error
            formatted_response += f"Error: {response_data['error']}\n" # Add the error message to the response

        return formatted_response # Return the final formatted response string


    def get_session_summary(self) -> Dict: # Define a method to get a summary of the current session
        """Return a summary of the current session data""" # Add a docstring explaining the method's purpose
        return { # Return a dictionary containing the session summary
            "session_id": self.shared_scratchpad["session_id"], # Add the session ID
            "total_interactions": len(self.shared_scratchpad["user_interactions"]), # Add the total number of user interactions
            "agent_outputs": self.shared_scratchpad["agent_outputs"], # Add the agent outputs
            "messages": self.shared_scratchpad["messages"], # Add the messages
            "user_interactions": self.shared_scratchpad["user_interactions"] # Add the user interactions
        }

"""# **Testing Framework**"""

class SupplyChainTestFramework: # Define a class named SupplyChainTestFramework
    """Comprehensive testing framework for the multi-agent system""" # Add a docstring explaining the framework's purpose

    def __init__(self, planner_agent: PlannerManagerAgent): # Define the constructor for the SupplyChainTestFramework class
        self.planner = planner_agent # Store the planner agent instance
        self.test_results = [] # Initialize an empty list to store test results

    def run_test_scenario(self, scenario_name: str, test_data: Dict, expected_outcomes: List[str]) -> Dict: # Define a method to run a single test scenario
        """Run a single test scenario""" # Add a docstring explaining the method's purpose

        print(f"\nðŸ§ª Running Test: {scenario_name}") # Print a message indicating the start of the test scenario
        print("="*50) # Print a separator line

        start_time = time.time() # Record the start time of the test

        try: # Start a try block to handle potential errors during the test
            if "inventory_modifications" in test_data: # Check if there are any inventory modifications specified in the test data
                inventory_df = pd.read_csv('inventory.csv') # Load the inventory data from the CSV file
                for mod in test_data["inventory_modifications"]: # Iterate through each modification in the test data
                    idx = inventory_df[inventory_df['item_id'] == mod['item_id']].index[0] # Find the index of the item to be modified
                    inventory_df.loc[idx, mod['field']] = mod['value'] # Apply the modification to the specified field of the item
                inventory_df.to_csv('inventory.csv', index=False) # Save the modified inventory data back to the CSV file


            query = test_data.get("query", "Analyze current supply chain status") # Get the query from the test data, or use a default query if not provided
            result = self.planner.process_user_query(query) # Process the query using the planner agent

            passed_checks = [] # Initialize an empty list to store passed checks
            failed_checks = [] # Initialize an empty list to store failed checks

            for expected in expected_outcomes: # Iterate through each expected outcome
                if self._check_outcome(result, expected): # Check if the expected outcome occurred in the result
                    passed_checks.append(expected) # If the outcome occurred, add it to the passed checks list
                else: # If the expected outcome did not occur
                    failed_checks.append(expected) # Add the expected outcome to the failed checks list

            execution_time = time.time() - start_time # Calculate the execution time of the test

            test_result = { # Create a dictionary to store the test results
                "scenario": scenario_name, # Add the name of the test scenario
                "status": "PASS" if not failed_checks else "FAIL", # Determine the test status (PASS or FAIL)
                "execution_time": round(execution_time, 2), # Add the execution time (rounded to 2 decimal places)
                "passed_checks": passed_checks, # Add the list of passed checks
                "failed_checks": failed_checks, # Add the list of failed checks
                "agent_outputs": result.get("analysis_performed", []), # Add the list of analyses performed by the agents
                "recommendations": result.get("recommendations", []), # Add the recommendations generated by the planner
                "timestamp": datetime.now().isoformat() # Add the current timestamp
            }

            self.test_results.append(test_result) # Append the test result to the list of test results

            status_emoji = "âœ…" if test_result["status"] == "PASS" else "âŒ" # Determine the appropriate emoji based on the test status
            print(f"{status_emoji} {scenario_name}: {test_result['status']}") # Print the test scenario name and status
            print(f"â±ï¸  Execution time: {execution_time:.2f}s") # Print the execution time
            print(f"âœ… Passed: {len(passed_checks)}/{len(expected_outcomes)}") # Print the number of passed checks out of the total expected outcomes

            if failed_checks: # Check if there are any failed checks
                print(f"âŒ Failed checks: {', '.join(failed_checks)}") # Print the list of failed checks

            return test_result # Return the test result dictionary

        except Exception as e: # Catch any exceptions that occur during the test scenario
            error_result = { # Create a dictionary to store the error result
                "scenario": scenario_name, # Add the name of the test scenario
                "status": "ERROR", # Set the status to ERROR
                "error": str(e), # Add the error message
                "execution_time": time.time() - start_time, # Add the execution time
                "timestamp": datetime.now().isoformat() # Add the current timestamp
            }
            self.test_results.append(error_result) # Append the error result to the list of test results
            print(f"âŒ {scenario_name}: ERROR - {str(e)}") # Print an error message
            return error_result # Return the error result dictionary

    def _check_outcome(self, result: Dict, expected: str) -> bool: # Define an internal method to check if an expected outcome occurred
        """Check if expected outcome occurred""" # Add a docstring explaining the method's purpose

        if expected == "inventory_analysis_completed": # Check if the expected outcome is 'inventory_analysis_completed'
            return "inventory_analysis" in result.get("analysis_performed", []) # Return True if 'inventory_analysis' is in the list of performed analyses, otherwise False
        elif expected == "supplier_analysis_completed": # Check if the expected outcome is 'supplier_analysis_completed'
            return "supplier_analysis" in result.get("analysis_performed", []) # Return True if 'supplier_analysis' is in the list of performed analyses, otherwise False
        elif expected == "route_optimization_completed": # Check if the expected outcome is 'route_optimization_completed'
            return "route_optimization" in result.get("analysis_performed", []) # Return True if 'route_optimization' is in the list of performed analyses, otherwise False
        elif expected == "risk_assessment_completed": # Check if the expected outcome is 'risk_assessment_completed'
            return "risk_assessment" in result.get("analysis_performed", []) # Return True if 'risk_assessment' is in the list of performed analyses, otherwise False
        elif expected == "critical_items_identified": # Check if the expected outcome is 'critical_items_identified'
            return any("critical" in str(rec).lower() for rec in result.get("recommendations", [])) # Return True if any recommendation contains the word "critical" (case-insensitive), otherwise False
        elif expected == "suppliers_recommended": # Check if the expected outcome is 'suppliers_recommended'
            return "supplier" in str(result.get("analysis_performed", [])) # Return True if "supplier" is present in the string representation of the performed analyses, otherwise False (This check might be too broad and could be improved)
        elif expected == "routes_optimized": # Check if the expected outcome is 'routes_optimized'
            return "route" in str(result.get("analysis_performed", [])) # Return True if "route" is present in the string representation of the performed analyses, otherwise False (This check might be too broad and could be improved)
        elif expected == "risks_assessed": # Check if the expected outcome is 'risks_assessed'
            return "risk" in str(result.get("analysis_performed", [])) # Return True if "risk" is present in the string representation of the performed analyses, otherwise False (This check might be too broad and could be improved)

        return False # Return False if the expected outcome is not recognized

    def run_all_tests(self) -> Dict: # Define a method to run all test scenarios
        """Run all test scenarios""" # Add a docstring explaining the method's purpose

        print("ðŸš€ Starting Supply Chain Optimizer Test Suite") # Print a message indicating the start of the test suite
        print("="*60) # Print a separator line

        test1_data = { # Define the data for the first test scenario (Normal Operation)
            "query": "Analyze current supply chain status", # The query for this scenario
            "inventory_modifications": [] # No inventory modifications for this scenario
        }
        test1_expected = [ # Define the expected outcomes for the first test scenario
            "inventory_analysis_completed", # Expect inventory analysis to be completed
            "supplier_analysis_completed", # Expect supplier analysis to be completed
            "route_optimization_completed", # Expect route optimization to be completed
            "risk_assessment_completed" # Expect risk assessment to be completed
        ]

        test2_data = { # Define the data for the second test scenario (Supplier Delay)
            "query": "Handle supplier delay for critical items", # The query for this scenario
            "inventory_modifications": [ # Inventory modifications for this scenario
                {"item_id": "SKU001", "field": "current_stock", "value": 15} # Modify the current stock of item SKU001
            ]
        }
        test2_expected = [ # Define the expected outcomes for the second test scenario
            "inventory_analysis_completed", # Expect inventory analysis to be completed
            "critical_items_identified", # Expect critical items to be identified
            "suppliers_recommended" # Expect suppliers to be recommended
        ]


        test3_data = { # Define the data for the third test scenario (Demand Spike)
            "query": "Handle increased demand for popular items", # The query for this scenario
            "inventory_modifications": [ # Inventory modifications for this scenario
                {"item_id": "SKU002", "field": "monthly_usage", "value": 80}, # Modify monthly usage of item SKU002
                {"item_id": "SKU005", "field": "monthly_usage", "value": 60} # Modify monthly usage of item SKU005
            ]
        }
        test3_expected = [ # Define the expected outcomes for the third test scenario
            "inventory_analysis_completed", # Expect inventory analysis to be completed
            "critical_items_identified", # Expect critical items to be identified
            "routes_optimized" # Expect routes to be optimized
        ]

        test4_data = { # Define the data for the fourth test scenario (Weather Disruption)
            "query": "Assess impact of severe weather on delivery routes", # The query for this scenario
        }
        test4_expected = [ # Define the expected outcomes for the fourth test scenario
            "risk_assessment_completed", # Expect risk assessment to be completed
            "routes_optimized", # Expect routes to be optimized
            "risks_assessed" # Expect risks to be assessed
        ]

        test5_data = { # Define the data for the fifth test scenario (Emergency Stockout)
            "query": "Emergency response for multiple stockouts", # The query for this scenario
            "inventory_modifications": [ # Inventory modifications for this scenario
                {"item_id": "SKU001", "field": "current_stock", "value": 5}, # Modify current stock of item SKU001
                {"item_id": "SKU003", "field": "current_stock", "value": 10}, # Modify current stock of item SKU003
                {"item_id": "SKU007", "field": "current_stock", "value": 20} # Modify current stock of item SKU007
            ]
        }
        test5_expected = [ # Define the expected outcomes for the fifth test scenario
            "inventory_analysis_completed", # Expect inventory analysis to be completed
            "critical_items_identified", # Expect critical items to be identified
            "suppliers_recommended", # Expect suppliers to be recommended
            "routes_optimized" # Expect routes to be optimized
        ]

        scenarios = [ # Create a list of all test scenarios
            ("Normal Operation", test1_data, test1_expected), # Add the Normal Operation scenario
            ("Supplier Delay", test2_data, test2_expected), # Add the Supplier Delay scenario
            ("Demand Spike", test3_data, test3_expected), # Add the Demand Spike scenario
            ("Weather Disruption", test4_data, test4_expected), # Add the Weather Disruption scenario
            ("Emergency Stockout", test5_data, test5_expected) # Add the Emergency Stockout scenario
        ]

        for scenario_name, test_data, expected in scenarios: # Iterate through each test scenario
            self.run_test_scenario(scenario_name, test_data, expected) # Run the current test scenario
            time.sleep(1) # Pause for 1 second between tests

        summary = self._generate_test_summary() # Generate a summary of all test results

        with open('test_results.json', 'w') as f: # Open a file named 'test_results.json' in write mode
            json.dump({ # Write the test summary and detailed results to the file in JSON format
                "summary": summary, # Add the test summary
                "detailed_results": self.test_results # Add the detailed test results
            }, f, indent=2) # Use indentation for readability

        print("\n" + "="*60) # Print a separator line
        print("ðŸ“Š TEST SUITE COMPLETE") # Print a message indicating the test suite is complete
        print(f"âœ… Passed: {summary['passed']}/{summary['total']}") # Print the number of passed tests
        print(f"âŒ Failed: {summary['failed']}/{summary['total']}") # Print the number of failed tests
        print(f"â±ï¸  Total time: {summary['total_time']:.2f}s") # Print the total execution time
        print("ðŸ“„ Results saved to test_results.json") # Confirm that the results have been saved

        return summary # Return the test summary dictionary

    def _generate_test_summary(self) -> Dict: # Define an internal method to generate test summary statistics
        """Generate test summary statistics""" # Add a docstring explaining the method's purpose
        total = len(self.test_results) # Get the total number of test results
        passed = len([r for r in self.test_results if r["status"] == "PASS"]) # Count the number of tests with status 'PASS'
        failed = len([r for r in self.test_results if r["status"] in ["FAIL", "ERROR"]]) # Count the number of tests with status 'FAIL' or 'ERROR'
        total_time = sum(r.get("execution_time", 0) for r in self.test_results) # Calculate the total execution time of all tests

        return { # Return a dictionary containing the test summary statistics
            "total": total, # Add the total number of tests
            "passed": passed, # Add the number of passed tests
            "failed": failed, # Add the number of failed tests
            "pass_rate": round(passed/total*100, 1) if total > 0 else 0, # Calculate the pass rate (percentage)
            "total_time": total_time, # Add the total execution time
            "average_time": round(total_time/total, 2) if total > 0 else 0 # Calculate the average execution time per test
        }


print("ðŸ§ª Test framework ready!") # Print a message indicating that the test framework is ready

"""# **Visualization Components**"""

import matplotlib.pyplot as plt # Import the matplotlib.pyplot module and alias it as plt for creating plots
import pandas as pd # Import the pandas library and alias it as pd for data manipulation
import numpy as np # Import the numpy library and alias it as np for numerical operations
import folium # Import the folium library for creating interactive maps
import seaborn as sns # Import the seaborn library for statistical data visualization
from typing import List, Dict # Import type hints for better code readability and maintainability

class SupplyChainVisualizer: # Define a class named SupplyChainVisualizer
    """Create visualizations for supply chain data and analysis""" # Add a docstring explaining the purpose of the class

    def __init__(self): # Define the constructor for the SupplyChainVisualizer class
        plt.style.use('default') # Set the matplotlib style to 'default'

    def create_inventory_chart(self, inventory_df: pd.DataFrame) -> None: # Define a method to create an inventory status chart
        """Create inventory status chart""" # Add a docstring explaining the method's purpose

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6)) # Create a figure and a set of subplots with 1 row and 2 columns

        items = inventory_df['item_name'] # Get the 'item_name' column from the inventory DataFrame
        current = inventory_df['current_stock'] # Get the 'current_stock' column from the inventory DataFrame
        reorder = inventory_df['reorder_point'] # Get the 'reorder_point' column from the inventory DataFrame

        x = np.arange(len(items)) # Create an array of evenly spaced values from 0 to the number of items
        width = 0.35 # Set the width of the bars in the bar chart

        ax1.bar(x - width/2, current, width, label='Current Stock', color='skyblue') # Create a bar chart for current stock
        ax1.bar(x + width/2, reorder, width, label='Reorder Point', color='lightcoral') # Create a bar chart for reorder points
        ax1.set_xlabel('Items') # Set the label for the x-axis
        ax1.set_ylabel('Quantity') # Set the label for the y-axis
        ax1.set_title('Current Stock vs Reorder Points') # Set the title of the first subplot
        ax1.set_xticks(x) # Set the tick locations on the x-axis
        ax1.set_xticklabels(items, rotation=45, ha='right') # Set the tick labels on the x-axis with rotation
        ax1.legend() # Display the legend
        ax1.grid(True, alpha=0.3) # Add a grid to the plot

        inventory_df_copy = inventory_df.copy() # Create a copy of the inventory DataFrame
        inventory_df_copy['days_until_stockout'] = ( # Calculate 'days_until_stockout' column
            inventory_df_copy['current_stock'] / inventory_df_copy['monthly_usage'] * 30 # Calculate days until stockout
        )

        colors = ['red' if days <= 14 else 'orange' if days <= 30 else 'green' # Determine bar colors based on days until stockout
                 for days in inventory_df_copy['days_until_stockout']]

        ax2.bar(items, inventory_df_copy['days_until_stockout'], color=colors) # Create a bar chart for days until stockout
        ax2.set_xlabel('Items') # Set the label for the x-axis
        ax2.set_ylabel('Days Until Stockout') # Set the label for the y-axis
        ax2.set_title('Days Until Stockout by Item') # Set the title of the second subplot
        ax2.set_xticklabels(items, rotation=45, ha='right') # Set the tick labels on the x-axis with rotation
        ax2.axhline(y=14, color='red', linestyle='--', alpha=0.7, label='Critical (14 days)') # Add a horizontal line for the critical threshold
        ax2.axhline(y=30, color='orange', linestyle='--', alpha=0.7, label='Warning (30 days)') # Add a horizontal line for the warning threshold
        ax2.legend() # Display the legend
        ax2.grid(True, alpha=0.3) # Add a grid to the plot

        plt.tight_layout() # Adjust layout to prevent labels overlapping
        plt.show() # Display the plot

    def create_supplier_comparison(self, suppliers_df: pd.DataFrame) -> None: # Define a method to create a supplier comparison visualization
        """Create supplier comparison visualization""" # Add a docstring explaining the method's purpose

        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12)) # Create a figure and a 2x2 grid of subplots

        supplier_reliability = suppliers_df.groupby('supplier_name')['reliability_score'].mean() # Calculate the average reliability score for each supplier

        ax1.bar(supplier_reliability.index, supplier_reliability.values, color='lightgreen') # Create a bar chart for supplier reliability
        ax1.set_title('Supplier Reliability Scores') # Set the title of the first subplot
        ax1.set_ylabel('Reliability Score') # Set the label for the y-axis
        ax1.set_ylim(0, 1) # Set the limits for the y-axis
        ax1.tick_params(axis='x', rotation=45) # Rotate x-axis tick labels
        for i, v in enumerate(supplier_reliability.values): # Add text labels for reliability scores on the bars
            ax1.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom')

        supplier_leadtime = suppliers_df.groupby('supplier_name')['lead_time_days'].mean() # Calculate the average lead time for each supplier

        ax2.bar(supplier_leadtime.index, supplier_leadtime.values, color='lightblue') # Create a bar chart for average lead times
        ax2.set_title('Average Lead Times') # Set the title of the second subplot
        ax2.set_ylabel('Days') # Set the label for the y-axis
        ax2.tick_params(axis='x', rotation=45) # Rotate x-axis tick labels
        for i, v in enumerate(supplier_leadtime.values): # Add text labels for average lead times on the bars
            ax2.text(i, v + 0.1, f'{v:.1f}', ha='center', va='bottom')

        ax3.hist(suppliers_df['price_per_unit'], bins=10, color='lightyellow', edgecolor='black') # Create a histogram for the distribution of prices per unit
        ax3.set_title('Price Distribution') # Set the title of the third subplot
        ax3.set_xlabel('Price per Unit ($)') # Set the label for the x-axis
        ax3.set_ylabel('Frequency') # Set the label for the y-axis

        item_count = suppliers_df.groupby('supplier_name')['item_id'].count() # Count the number of items supplied by each supplier

        ax4.pie(item_count.values, labels=item_count.index, autopct='%1.1f%%', startangle=90) # Create a pie chart showing the proportion of items supplied by each supplier
        ax4.set_title('Items Supplied by Each Supplier') # Set the title of the fourth subplot

        plt.tight_layout() # Adjust layout to prevent labels overlapping
        plt.show() # Display the plot

    def create_route_map(self, locations: List[tuple], route_data: Dict = None) -> folium.Map: # Define a method to create an interactive map showing delivery routes
        """Create interactive map showing delivery routes""" # Add a docstring explaining the method's purpose

        if not locations: # Check if the locations list is empty
            return None # Return None if no locations are provided

        center_lat = sum(lat for lat, lon in locations) / len(locations) # Calculate the average latitude for centering the map
        center_lon = sum(lon for lat, lon in locations) / len(locations) # Calculate the average longitude for centering the map

        m = folium.Map(location=[center_lat, center_lon], zoom_start=11) # Create a Folium map centered at the calculated coordinates

        for i, (lat, lon) in enumerate(locations): # Iterate through each location with its index
            folium.Marker( # Add a marker for each location on the map
                [lat, lon], # Set the coordinates of the marker
                popup=f'Stop {i+1}: ({lat:.4f}, {lon:.4f})', # Set the popup text for the marker
                tooltip=f'Stop {i+1}', # Set the tooltip text for the marker
                icon=folium.Icon(color='blue' if i == 0 else 'red' if i == len(locations)-1 else 'green') # Set the icon color based on whether it's the start, end, or an intermediate stop
            ).add_to(m) # Add the marker to the map

        folium.PolyLine(locations, color='blue', weight=2, opacity=0.7).add_to(m) # Add a polyline connecting the locations to represent the route

        if route_data: # Check if route data is provided
            info_html = f""" # Create an HTML string for displaying route information on the map
            <div style='position: fixed;
                        top: 10px; left: 50px; width: 300px; height: 120px;
                        background-color: white; border:2px solid grey; z-index:9999;
                        font-size:14px; padding: 10px'>
            <h4>Route Information</h4>
            <b>Distance:</b> {route_data.get('total_distance_km', 'N/A')} km<br>
            <b>Duration:</b> {route_data.get('estimated_duration_hours', 'N/A')} hours<br>
            <b>Cost:</b> ${route_data.get('total_cost_usd', 'N/A')}<br>
            <b>Waypoints:</b> {route_data.get('waypoints', len(locations))}
            </div>
            """
            m.get_root().html.add_child(folium.Element(info_html)) # Add the HTML information box to the map

        return m # Return the created Folium map

    def create_risk_heatmap(self, risk_data: Dict) -> None: # Define a method to create a risk assessment heatmap
        """Create risk assessment heatmap""" # Add a docstring explaining the method's purpose

        risk_categories = ['Weather', 'Supplier', 'Transport', 'Demand', 'Financial'] # Define the list of risk categories
        risk_levels = ['Low', 'Medium', 'High'] # Define the list of risk levels
        risk_matrix = np.array([ # Define a NumPy array representing the risk matrix (example data)
            [0.2, 0.6, 0.2], # Probabilities for Weather risk levels
            [0.7, 0.25, 0.05], # Probabilities for Supplier risk levels
            [0.5, 0.4, 0.1], # Probabilities for Transport risk levels
            [0.3, 0.5, 0.2], # Probabilities for Demand risk levels
            [0.8, 0.15, 0.05] # Probabilities for Financial risk levels
        ])

        fig, ax = plt.subplots(figsize=(10, 6)) # Create a figure and a single subplot

        im = ax.imshow(risk_matrix, cmap='RdYlGn_r', aspect='auto') # Display the risk matrix as a heatmap using a colormap

        ax.set_xticks(np.arange(len(risk_levels))) # Set the tick locations on the x-axis
        ax.set_yticks(np.arange(len(risk_categories))) # Set the tick locations on the y-axis
        ax.set_xticklabels(risk_levels) # Set the tick labels on the x-axis
        ax.set_yticklabels(risk_categories) # Set the tick labels on the y-axis

        for i in range(len(risk_categories)): # Iterate through rows of the risk matrix
            for j in range(len(risk_levels)): # Iterate through columns of the risk matrix
                text = ax.text(j, i, f'{risk_matrix[i, j]:.2f}', # Add text labels (probabilities) to each cell of the heatmap
                             ha="center", va="center", color="black", fontweight="bold")

        ax.set_title("Supply Chain Risk Assessment Matrix", fontsize=16, pad=20) # Set the title of the heatmap
        ax.set_xlabel("Risk Level", fontsize=12) # Set the label for the x-axis
        ax.set_ylabel("Risk Category", fontsize=12) # Set the label for the y-axis

        cbar = plt.colorbar(im, ax=ax) # Add a colorbar to the heatmap
        cbar.set_label('Probability', rotation=270, labelpad=20) # Set the label for the colorbar

        plt.tight_layout() # Adjust layout to prevent labels overlapping
        plt.show() # Display the plot

    def create_tradeoff_scorecard(self, analysis_data: Dict) -> None: # Define a method to create a trade-off scorecard visualization
        """Create trade-off scorecard visualization""" # Add a docstring explaining the method's purpose
        # Example scores - these would ideally be derived from analysis_data
        cost_score = 0.8 # Example score for cost
        time_score = 0.7 # Example score for time
        risk_score = 0.6 # Example score for risk
        reliability_score = 0.9 # Example score for reliability

        categories = ['Cost', 'Time', 'Risk', 'Reliability'] # Define the list of categories for the scorecard
        scores = [cost_score, time_score, risk_score, reliability_score] # Create a list of scores
        colors = ['green' if s >= 0.8 else 'orange' if s >= 0.6 else 'red' for s in scores] # Determine bar colors based on scores

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6)) # Create a figure and a set of subplots with 1 row and 2 columns

        bars = ax1.bar(categories, scores, color=colors) # Create a bar chart for the tradeoff scores
        ax1.set_ylim(0, 1) # Set the limits for the y-axis
        ax1.set_title('Supply Chain Trade-off Scorecard', fontsize=14, fontweight='bold') # Set the title of the first subplot
        ax1.set_ylabel('Score (0-1)') # Set the label for the y-axis
        ax1.grid(True, alpha=0.3) # Add a grid to the plot

        for bar, score in zip(bars, scores): # Add text labels for scores on the bars
            height = bar.get_height() # Get the height of the bar
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01, # Position the text label
                    f'{score:.2f}', ha='center', va='bottom', fontweight='bold') # Format and add the text label

        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist() # Calculate the angles for the radar chart
        scores_radar = scores + [scores[0]] # Close the loop for the radar chart by adding the first score at the end
        angles += angles[:1] # Close the loop for the angles

        ax2.plot(angles, scores_radar, 'o-', linewidth=2, color='blue') # Create the radar chart line
        ax2.fill(angles, scores_radar, alpha=0.25, color='blue') # Fill the area under the radar chart line
        ax2.set_xticks(angles[:-1]) # Set the tick locations on the x-axis (angles)
        ax2.set_xticklabels(categories) # Set the tick labels (categories) on the x-axis
        ax2.set_ylim(0, 1) # Set the limits for the y-axis
        ax2.set_title('Performance Radar Chart', fontsize=14, fontweight='bold') # Set the title of the second subplot
        ax2.grid(True) # Add a grid to the plot

        plt.tight_layout() # Adjust layout to prevent labels overlapping
        plt.show() # Display the plot


print("ðŸ“Š Visualization components ready!") # Print a message indicating that the visualization components are ready

def main_pipeline():
    """Main execution pipeline for the supply chain optimizer"""

    print("ðŸš€ MULTI-AGENT SMART SUPPLY CHAIN OPTIMIZER") # Print a header for the pipeline
    print("=" * 60) # Print a separator line
    print(f"Mode: {'STATIC' if STATIC_MODE else 'DYNAMIC'}") # Print the operating mode (STATIC or DYNAMIC)
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}") # Print the current timestamp
    print("=" * 60) # Print a separator line

    bus = CommunicationBus() # Initialize the communication bus for agents to talk to each other

    planner = PlannerManagerAgent(llm, bus) # Initialize the main planner agent, which orchestrates the other agents
    visualizer = SupplyChainVisualizer() # Initialize the visualizer for creating charts and maps
    test_framework = SupplyChainTestFramework(planner) # Initialize the test framework for running test scenarios

    inventory_df = pd.read_csv('inventory.csv') # Load inventory data from the CSV file
    suppliers_df = pd.read_csv('suppliers.csv') # Load supplier data from the CSV file

    # Generate random latitude and longitude pairs for all items in the inventory
    num_items = len(inventory_df)
    random_lat = np.random.uniform(10, 35, num_items) # Generate random latitudes between 10 and 35
    random_lon = np.random.uniform(70, 97, num_items) # Generate random longitudes between 70 and 97

    # Assign the generated random coordinates to the 'location_lat' and 'location_lon' columns
    inventory_df['location_lat'] = random_lat
    inventory_df['location_lon'] = random_lon

    # Save the updated inventory DataFrame back to the CSV file
    inventory_df.to_csv('inventory.csv', index=False)

    print("\nðŸ“Š INITIAL DATA OVERVIEW (using updated locations)") # Print a header for the initial data overview
    print("-" * 30) # Print a separator line
    print(f"Inventory items: {len(inventory_df)}") # Print the total number of inventory items
    print(f"Suppliers: {len(suppliers_df['supplier_name'].unique())}") # Print the number of unique suppliers
    print(f"Total stock value: {inventory_df['current_stock'].sum():,} units") # Print the total current stock value

    print("\nðŸ“ˆ GENERATING VISUALIZATIONS") # Print a header for the visualization section
    print("-" * 30) # Print a separator line

    print("Creating inventory status chart...") # Indicate that the inventory chart is being created
    visualizer.create_inventory_chart(inventory_df) # Create the inventory status chart

    print("Creating supplier comparison...") # Indicate that the supplier comparison is being created
    visualizer.create_supplier_comparison(suppliers_df) # Create the supplier comparison visualization

    print("Creating risk assessment heatmap...") # Indicate that the risk assessment heatmap is being created
    visualizer.create_risk_heatmap({}) # Create the risk assessment heatmap (passing an empty dict for now)

    print("\nðŸ¤– RUNNING INITIAL ANALYSIS") # Print a header for the initial analysis section
    print("-" * 30) # Print a separator line

    initial_query = "Analyze current supply chain status and provide recommendations" # Define the initial query for the planner agent
    result = planner.process_user_query(initial_query) # Process the initial query using the planner agent

    print("\nðŸ“‹ ANALYSIS RESULTS:") # Print a header for the analysis results
    for i, rec in enumerate(result.get("recommendations", []), 1): # Iterate through the recommendations from the result
        print(f"{i}. {rec}") # Print each recommendation

    if "route" in planner.shared_scratchpad["agent_outputs"]: # Check if route optimization results are available in the planner's scratchpad
        print("\nCreating route optimization map...") # Indicate that the route optimization map is being created
        # Extract location coordinates from the inventory DataFrame for map visualization
        locations_for_map = [(row['location_lat'], row['location_lon']) for index, row in inventory_df.iterrows()]
        # Get the route data from the planner's scratchpad
        route_data = planner.shared_scratchpad["agent_outputs"]["route"]
        if locations_for_map: # Check if there are locations available for the map
            route_map = visualizer.create_route_map(locations_for_map, route_data) # Create the interactive route map
            if route_map: # Check if the route map was successfully created
                route_map.save('supply_chain_route_map.html') # Save the route map as an HTML file
                print("ðŸ“ Route map saved as 'supply_chain_route_map.html'") # Confirm that the map was saved
        else: # If no locations are available
            logger.warning("No locations available to create route map.") # Log a warning

    print("\nCreating trade-off scorecard...") # Indicate that the trade-off scorecard is being created
    visualizer.create_tradeoff_scorecard(planner.shared_scratchpad["agent_outputs"]) # Create the trade-off scorecard visualization

    print("\nðŸ§ª RUNNING COMPREHENSIVE TEST SUITE") # Print a header for the test suite section
    print("-" * 30) # Print a separator line

    test_summary = test_framework.run_all_tests() # Run all test scenarios using the test framework

    print("\nðŸ“„ GENERATING FINAL OUTPUT") # Print a header for the final output section
    print("-" * 30) # Print a separator line

    final_output = generate_final_output(planner, test_summary) # Generate the comprehensive final output

    save_session_data(planner, test_summary, final_output) # Save all session data, test summary, and final output to files

    print("\nâœ… PIPELINE COMPLETE!") # Indicate that the pipeline has completed successfully
    print("All results saved to files.") # Confirm that results have been saved

    return final_output # Return the generated final output

def generate_final_output(planner: PlannerManagerAgent, test_summary: Dict) -> Dict:
    """Generate comprehensive final output"""  # Define a function to create a comprehensive final output

    session_data = planner.get_session_summary()  # Get the summary of the current session data from the planner agent
    agent_outputs = session_data.get("agent_outputs", {})  # Get the outputs from all agents during the session, default to empty dict if not available

    final_output = {  # Create a dictionary to store the final output results
        "inventory_status": {},  # Initialize an empty dictionary for inventory status
        "supplier_recommendation": {},  # Initialize an empty dictionary for supplier recommendations
        "optimized_route": {},  # Initialize an empty dictionary for optimized route details
        "risk_alerts": [],  # Initialize an empty list for risk alerts
        "final_plan": "",  # Initialize an empty string for the structured final plan
        "planner_user_dialogue": session_data.get("user_interactions", []),  # Add the user interactions from the session data
        "tradeoff_scorecard": {  # Initialize a dictionary for the tradeoff scorecard with example scores
            "cost": 0.8,  # Example cost score
            "time": 0.7,  # Example time score
            "risk": 0.6,  # Example risk score
            "trust_score": 0.85  # Example trust score
        },
        "human_explanation": "",  # Initialize an empty string for the human-readable explanation
        "human_final_plan": "",  # Initialize an empty string for the human-readable final plan
        "test_summary": test_summary  # Add the test summary data
    }

    if "inventory" in agent_outputs:  # Check if inventory analysis results are available in the agent outputs
        inv = agent_outputs["inventory"]  # Get the inventory analysis data
        final_output["inventory_status"] = {  # Populate the inventory_status dictionary
            "total_items": inv["total_items"],  # Add the total number of items
            "critical_items": inv["critical_items"],  # Add the number of critical items
            "low_stock_items": inv["low_stock_items"],  # Add the number of low stock items
            "critical_item_details": inv["critical_item_details"]  # Add the details of critical items
        }

    if "supplier" in agent_outputs and agent_outputs["supplier"].get("recommended_suppliers"):  # Check if supplier recommendations are available
        sup_data = agent_outputs["supplier"]["recommended_suppliers"]  # Get the recommended suppliers data
        if sup_data:  # Check if there is any supplier data
            best_supplier = sup_data[0]  # Get the first recommended supplier (assuming it's the best)
            final_output["supplier_recommendation"] = {  # Populate the supplier_recommendation dictionary
                "item_id": best_supplier.get("item_id", "N/A"),  # Add the item ID (default to N/A if not found)
                "supplier_id": best_supplier.get("supplier_name", "N/A")[:6].upper(),  # Add a truncated and uppercase supplier ID
                "supplier_name": best_supplier.get("supplier_name", "N/A"),  # Add the supplier name
                "reasoning": [  # Add a list of reasoning points for the recommendation
                    f"Reliability score: {best_supplier.get('reliability_score', 0):.2f}",  # Add the reliability score
                    f"Price per unit: ${best_supplier.get('price_per_unit', 0):.2f}",  # Add the price per unit
                    f"Lead time: {best_supplier.get('lead_time_days', 0)} days"  # Add the lead time in days
                ],
                "score": best_supplier.get("reliability_score", 0)  # Add the reliability score as a separate field
            }


    if "route" in agent_outputs:  # Check if route optimization results are available
        route = agent_outputs["route"]  # Get the route optimization data
        final_output["optimized_route"] = {  # Populate the optimized_route dictionary
            "route_id": route.get("route_id", "N/A"),  # Add the route ID
            "total_distance_km": route.get("total_distance_km", "N/A"),  # Add the total distance
            "estimated_duration_hours": route.get("estimated_duration_hours", "N/A"),  # Add the estimated duration
            "total_cost_usd": route.get("total_cost_usd", "N/A"),  # Add the total cost
            "efficiency_score": route.get("efficiency_score", "N/A"),  # Add the efficiency score
            "status": route.get("status", "Optimal")  # Add the route status (default to Optimal)
        }

    if "risk" in agent_outputs and agent_outputs["risk"].get("weather_risks"):  # Check if risk analysis results and weather risks are available
        risk = agent_outputs["risk"]  # Get the risk analysis data
        final_output["risk_alerts"] = []  # Initialize an empty list for risk alerts
        for wr in risk["weather_risks"]:  # Iterate through each weather risk
             if wr["risk_level"] in ["high", "medium"]:  # Check if the weather risk level is high or medium
                 final_output["risk_alerts"].append({  # Append a dictionary for the risk alert
                     "risk_type": "weather",  # Add the risk type as 'weather'
                     "severity": wr["risk_level"],  # Add the severity of the risk
                     "location": wr["location"],  # Add the location of the risk
                     "condition": wr["condition"],  # Add the weather condition
                     "mitigation": wr["mitigation"]  # Add the recommended mitigation steps
                 })
        if risk.get("overall_risk_level"):  # Check if the overall risk level is available
             final_output["risk_alerts"].append({  # Append a dictionary for the overall risk alert
                 "risk_type": "overall",  # Add the risk type as 'overall'
                 "severity": risk["overall_risk_level"],  # Add the overall risk level
                 "mitigation": "Review detailed risk analysis and recommendations"  # Add a general mitigation step
             })

    final_output["human_explanation"] = generate_human_explanation(agent_outputs)  # Generate a human-readable explanation and add it to the output
    final_output["human_final_plan"] = generate_human_final_plan(agent_outputs)  # Generate a human-readable final plan and add it to the output
    final_output["final_plan"] = generate_structured_plan(agent_outputs)  # Generate a structured final plan and add it to the output

    return final_output  # Return the complete final output dictionary

def generate_human_explanation(agent_outputs: Dict) -> str: # Define a function to create a human-readable explanation
    """Generate human-readable explanation""" # Add a docstring explaining the function's purpose

    explanation = "ðŸ” SUPPLY CHAIN ANALYSIS SUMMARY\n\n" # Initialize the explanation string with a header

    if "inventory" in agent_outputs: # Check if inventory analysis results are available
        inv = agent_outputs["inventory"] # Get the inventory analysis data
        explanation += f"ðŸ“¦ INVENTORY: Analyzed {inv['total_items']} items. " # Add inventory analysis summary

        if inv["critical_items"] > 0: # Check if there are any critical items
            explanation += f"Found {inv['critical_items']} critical items below reorder points requiring immediate attention. " # Add details about critical items

        if inv["low_stock_items"] > 0: # Check if there are any low stock items
            explanation += f"Identified {inv['low_stock_items']} items with low stock levels (less than 14 days supply). " # Add details about low stock items

        explanation += f"Average inventory can sustain operations for {inv['average_days_to_stockout']:.0f} days.\n\n" # Add average days to stockout


    if "supplier" in agent_outputs and agent_outputs["supplier"].get("recommended_suppliers"): # Check if supplier recommendations are available
        sup_data = agent_outputs["supplier"]["recommended_suppliers"] # Get the recommended suppliers data
        if sup_data: # Check if there is any supplier data
            explanation += f"ðŸ­ SUPPLIERS: Evaluated suppliers for critical items. " # Add supplier analysis summary
            recommended_suppliers_list = ", ".join([s['recommended_supplier'] for s in sup_data]) # Create a comma-separated list of recommended supplier names
            explanation += f"Recommended suppliers include: {recommended_suppliers_list}.\n\n" # Add the list of recommended suppliers


    if "route" in agent_outputs: # Check if route optimization results are available
        route = agent_outputs["route"] # Get the route optimization data
        explanation += f"ðŸšš LOGISTICS: Optimized route covers {route['total_distance_km']} km " # Add route optimization summary (distance)
        explanation += f"in {route['estimated_duration_hours']:.1f} hours for ${route['total_cost_usd']:.0f} total cost.\n\n" # Add route optimization summary (duration and cost)

    if "risk" in agent_outputs: # Check if risk analysis results are available
        risk = agent_outputs["risk"] # Get the risk analysis data
        explanation += f"âš ï¸  RISKS: Overall risk level assessed as {risk['overall_risk_level'].upper()}. " # Add risk analysis summary (overall risk level)
        explanation += f"Primary concerns include weather conditions and potential supplier delays.\n\n" # Add primary risk concerns

    explanation += "ðŸ’¡ The system has analyzed all aspects of your supply chain and provided optimized recommendations balancing cost, time, and risk factors." # Add a concluding sentence

    return explanation # Return the generated explanation string


def generate_human_final_plan(agent_outputs: Dict) -> str: # Define a function to create a human-readable final plan
    """Generate human-readable final plan""" # Add a docstring explaining the function's purpose

    plan = "âš¡ FINAL OPTIMIZED SUPPLY CHAIN PLAN\n\n" # Initialize the plan string with a header

    critical_items = 0 # Initialize critical items count to 0
    if "inventory" in agent_outputs: # Check if inventory analysis results are available
        critical_items = agent_outputs["inventory"]["critical_items"] # Get the number of critical items

    if critical_items > 0: # Check if there are any critical items
        plan += f"ðŸ”¥ IMMEDIATE ACTIONS:\n" # Add a header for immediate actions
        plan += f"â€¢ Expedite restocking of {critical_items} critical items\n" # Add an action to expedite restocking
        plan += f"â€¢ Contact recommended suppliers for emergency orders\n" # Add an action to contact recommended suppliers
        plan += f"â€¢ Implement express shipping for fastest delivery\n\n" # Add an action to implement express shipping

    plan += f"ðŸ“‹ STRATEGIC RECOMMENDATIONS:\n" # Add a header for strategic recommendations

    if "supplier" in agent_outputs and agent_outputs["supplier"].get("recommended_suppliers"): # Check if supplier recommendations are available
        plan += f"â€¢ Utilize recommended suppliers for critical items.\n" # Add a recommendation to use recommended suppliers

    if "route" in agent_outputs: # Check if route optimization results are available
        route = agent_outputs["route"] # Get the route optimization data
        plan += f"â€¢ Follow optimized {route['total_distance_km']} km route for cost efficiency\n" # Add a recommendation to follow the optimized route (distance)
        plan += f"â€¢ Schedule deliveries within {route['estimated_duration_hours']:.0f} hour window\n" # Add a recommendation to schedule deliveries (duration)


    if "risk" in agent_outputs: # Check if risk analysis results are available
        risk = agent_outputs["risk"] # Get the risk analysis data
        plan += f"â€¢ Monitor {risk['overall_risk_level']} risk conditions closely\n" # Add a recommendation to monitor risk conditions
        plan += f"â€¢ Maintain contingency plans for weather disruptions\n" # Add a recommendation to maintain contingency plans

    plan += f"\nðŸŽ¯ This plan balances delivery speed, cost optimization, and risk mitigation to ensure reliable supply chain operations." # Add a concluding sentence for the plan

    return plan # Return the generated plan string

def generate_structured_plan(agent_outputs: Dict) -> str:
    """Generate structured plan summary"""  # Define a function to create a structured plan summary

    actions = []  # Create an empty list to hold the plan's action steps

    if "inventory" in agent_outputs:  # Check if inventory analysis results are available
        inv = agent_outputs["inventory"]  # Get the inventory analysis data
        if inv["critical_items"] > 0:  # Check if there are any critical items
            actions.append(f"Restock {inv['critical_items']} critical items immediately")  # Add an action to restock critical items

    if "supplier" in agent_outputs and agent_outputs["supplier"].get("recommended_suppliers"):  # Check if supplier recommendations are available
        actions.append(f"Review recommended suppliers for critical items")  # Add an action to review recommended suppliers

    if "route" in agent_outputs:  # Check if route optimization results are available
        route = agent_outputs["route"]  # Get the route optimization data
        actions.append(f"Execute {route['total_distance_km']} km optimized route")  # Add an action to execute the optimized route

    if "risk" in agent_outputs:  # Check if risk assessment results are available
        risk = agent_outputs["risk"]  # Get the risk assessment data
        actions.append(f"Monitor {risk['overall_risk_level']} risk conditions")  # Add an action to monitor risk conditions

    return " â†’ ".join(actions)  # Join all action steps with an arrow to form the final structured plan string

import numpy as np # Import the numpy library for numerical operations

def default_serializer(obj): # Define a function to handle serialization of non-standard types for JSON
    """Convert NumPy and Pandas types to native Python for JSON serialization""" # Add a docstring explaining the function's purpose
    if isinstance(obj, (np.int64, np.int32, np.float32, np.float64)): # Check if the object is a NumPy integer or float type
        return obj.item() # Convert NumPy number to a native Python number
    if hasattr(obj, "tolist"): # Check if the object has a 'tolist' method (common for NumPy arrays and Pandas Series/DataFrames)
        return obj.tolist() # Convert the object to a Python list
    return str(obj) # Convert any other object to a string

def save_session_data(planner: PlannerManagerAgent, test_summary: Dict, final_output: Dict): # Define a function to save session data to files
    """Save all session data to files safely with JSON serialization""" # Add a docstring explaining the function's purpose

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") # Get the current timestamp formatted as a string

    with open(f'supply_chain_analysis_{timestamp}.json', 'w') as f: # Open a file with a timestamped name for the final analysis output in write mode
        json.dump(final_output, f, indent=2, default=default_serializer) # Write the final_output dictionary to the file in JSON format, using the custom serializer and indentation

    session_data = planner.get_session_summary() # Get the summary of the current session data from the planner agent
    with open(f'session_summary_{timestamp}.json', 'w') as f: # Open a file with a timestamped name for the session summary in write mode
        json.dump(session_data, f, indent=2, default=default_serializer) # Write the session_data dictionary to the file in JSON format, using the custom serializer and indentation

    for agent in [planner.inventory_agent, planner.supplier_agent, planner.route_agent, planner.risk_agent]: # Iterate through each of the individual agents managed by the planner
        agent.memory.save_memory() # Call the save_memory method for each agent to save their individual memory to a file

    print(f"ðŸ’¾ All data saved with timestamp: {timestamp}") # Print a confirmation message indicating that all data has been saved with the timestamp

if __name__ == "__main__":
    try: # Start a try block to handle potential errors during the pipeline execution
        final_result = main_pipeline() # Call the main_pipeline function to run the supply chain optimization process
        print("\nðŸŽ‰ Supply Chain Optimizer completed successfully!") # Print a success message if the pipeline completes without errors

    except Exception as e: # Catch any exceptions that occur during the pipeline execution
        print(f"\nâŒ Error in main pipeline: {str(e)}") # Print an error message to the console
        logger.error(f"Main pipeline error: {str(e)}", exc_info=True) # Log the detailed error information, including the traceback

def interactive_demo():
    """Interactive demo allowing users to query the system"""
    bus = CommunicationBus()  # Initialize the communication bus for agents to talk to each other
    planner = PlannerManagerAgent(llm, bus)   # Initialize the main planner agent, which orchestrates the other agents
    print("\nðŸŽ® INTERACTIVE SUPPLY CHAIN OPTIMIZER DEMO")   # Print a welcoming message for the interactive demo
    print("=" * 50)
    print("Type 'help' for available commands, 'quit' to exit")   # Instruct the user on how to get help or exit the demo
    print("=" * 50)
    while True:        # Start an infinite loop to keep the demo running until the user quits
        try:       # Prompt the user for input and remove leading/trailing whitespace
            user_input = input("\nUser: ").strip()  # Prompt the user for input and remove leading/trailing whitespace
            if user_input.lower() == 'quit':     # Check if the user wants to quit the demo
                print("ðŸ‘‹ Goodbye!")   # Print a goodbye message and break out of the loop
                break
            # Check if the user needs help
            elif user_input.lower() == 'help':
                # Call the helper function to print available commands and examples
                print_help()
                # Continue to the next iteration of the loop
                continue
            # Check if the user wants to see the system status
            elif user_input.lower() == 'status':
                # Call the function to print the current system status
                print_system_status(planner)
                # Continue to the next iteration of the loop
                continue
            # Check if the user wants to see agent memory summaries
            elif user_input.lower() == 'memory':
                # Call the function to print summaries of agent memories
                print_agent_memories(planner)
                # Continue to the next iteration of the loop
                continue
            # If the user input is empty, continue to the next iteration
            elif not user_input:
                continue

            # If the input is not a command, process it as a user query
            print("\nðŸ¤– Planner Agent: Processing your request...")

            # Call the planner agent to process the user's query
            result = planner.process_user_query(user_input)

            # Print the analysis results provided by the planner agent
            print("\nðŸ“Š Analysis Results:")
            # Iterate through the recommendations in the result and print each one
            for i, rec in enumerate(result.get("recommendations", []), 1):
                print(f"   {i}. {rec}")

            # Check if there was an error during processing and print it
            if "error" in result:
                print(f"\nâŒ Error: {result['error']}")

        # Handle a keyboard interrupt (e.g., pressing Ctrl+C)
        except KeyboardInterrupt:
            # Print a message indicating the demo was interrupted and exit
            print("\n\nðŸ‘‹ Demo interrupted. Goodbye!")
            break
        # Catch any other exceptions that might occur
        except Exception as e:
            # Print an error message including the exception details
            print(f"\nâŒ Error: {str(e)}")


def print_help():
    """Print help information"""

    help_text = """
ðŸ†˜ AVAILABLE COMMANDS:

â€¢ help      - Show this help message
â€¢ quit      - Exit the demo
â€¢ status    - Show system status
â€¢ memory    - Show agent memory summaries

ðŸ“ EXAMPLE QUERIES:

â€¢ "Analyze current inventory status"
â€¢ "What items need restocking?"
â€¢ "Optimize routes for delivery"
â€¢ "Assess supply chain risks"
â€¢ "Why was supplier X recommended?"
â€¢ "Show me the cost breakdown"
"""
    print(help_text)


def print_system_status(planner):
    """Print current system status"""

    # Get the summary of the current session data from the planner agent
    session_data = planner.get_session_summary()

    # Print a header for the system status
    print("\nðŸ“Š SYSTEM STATUS:")
    # Print the current session ID
    print(f"   Session ID: {session_data['session_id']}")
    # Print the total number of interactions in the current session
    print(f"   Total Interactions: {session_data['total_interactions']}")
    # Print the current operating mode (STATIC or DYNAMIC)
    print(f"   Mode: {'STATIC' if STATIC_MODE else 'DYNAMIC'}")
    # Print the number of agents available in the system
    print(f"   Available Agents: 5 (Inventory, Supplier, Route, Risk, Planner)")

    # Check if there were any agent outputs in the last analysis
    if session_data["agent_outputs"]:
        # Print the keys of the last agent outputs, indicating which analyses were performed
        print(f"   Last Analysis: {', '.join(session_data['agent_outputs'].keys())}")


def print_agent_memories(planner):
    """Print agent memory summaries"""

    # Create a list of the individual agents managed by the planner
    agents = [planner.inventory_agent, planner.supplier_agent, planner.route_agent, planner.risk_agent]

    # Print a header for the agent memory summary
    print("\nðŸ§  AGENT MEMORY SUMMARY:")
    # Iterate through each agent
    for agent in agents:
        # Get the number of decisions recorded in the agent's memory
        decisions = len(agent.memory.memory.get("decisions", []))
        # Get the number of conversations recorded in the agent's memory
        conversations = len(agent.memory.memory.get("conversations", []))
        # Print the agent's name and the counts of decisions and conversations
        print(f"   {agent.name}: {decisions} decisions, {conversations} conversations")


# Print a message indicating that the Supply Chain Optimizer is ready
print("\nðŸŽ¯ Supply Chain Optimizer is ready!")
# Print separators for clarity
print("\n" + "="*60)
# Instruct the user on how to run the full analysis
print("TO RUN THE SYSTEM:")
print("1. Execute: main_pipeline()  - Run full analysis")
# Instruct the user on how to run the interactive demo
print("2. Execute: interactive_demo()  - Interactive mode")
# Print separators for clarity
print("="*60)

"""# **Run full analysis**"""

main_pipeline()

"""# **Interactive mode**"""

interactive_demo()